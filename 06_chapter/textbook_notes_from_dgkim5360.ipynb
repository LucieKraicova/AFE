{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6. Kernel Smoothing Methods\n",
    "\n",
    "In this chapter we describe a class of regression techniques that achieve flexibility in estimating the regression function $f(X)$ over the domain $\\mathbb{R}^p$ by fitting a different but simple model separately at each query point $x_0$. This is done for some neighborhood of the target point $x_0$ to fit the simple model, and in such a way that the resulting estimated function $\\hat{f}(X)$ is smooth in $\\mathbb{R}^p$.\n",
    "\n",
    "This localization is achieved via a weighting function or _kernel_ $K_\\lambda(x_0,x_i)$, which assigns a weight to $x_i$ based on its distance from $x_0$. The kernels $K_\\lambda$ are typically indexed by a paramter $\\lambda$ that dictates the width of the neighborhood. These _memory-based_ methods require in principle little or no training. The only paramter that needs to be determined from the training data is $\\lambda$. The model, however, is the entire training data set.\n",
    "\n",
    "We also discuss more general classes of kernel-based techniques, which tie in with structured methods in other chapters, and are useful for density estimation and classficiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caution, don't confuse!\n",
    "\n",
    "> In this chapter kernels are mostly used as a device for localization.\n",
    "\n",
    "The techniques in this chapter should not be confused with those associated with the more recent usage of the phrase \"kernel methods\". In this chapter kernels are mostly used as a device for localization. We discuss kernel methods in $\\S$ 5.8, 14.5.4, 18.5, and Chapter 12; in those contexts the kernel computes an inner product in a high-dimensional (implicit) feature space, and is used for regularized nonlinear modeling. We make some connections to the methodology in this chapter at the end of $\\S$ 6.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.1. One-Dimensional Kernel Smoothers\n",
    "\n",
    "In Chapter 2, we motivated the $k$-nearest-neighbor average\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x) = \\text{Ave}\\left( y_i|x_i\\in N_k(x) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "as an estimate of the regression function $\\text{E}(Y|X=x)$. The idea is to relax the definition of conditional expectation, as illustrated in the left panel of FIGURE 6.1, and compute an average in a neighborhood of the target point.\n",
    "\n",
    "The KNN average changes in a discrete way, leading to a discontinuous $\\hat{f}$, which is ugly and unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# K-nearest neighbors (Section 2.3)\n",
    "def knn(k: int, point:float,\n",
    "        data_x:scipy.ndarray, data_y:scipy.ndarray) -> float:\n",
    "    idx_sorted = scipy.argsort((data_x-point)*(data_x-point))[:k]\n",
    "    return data_y[idx_sorted].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"FIGURE 6.1. (The left panel) The result of 30-NN running-mean smoother\n",
    "The green curve is bumpy, since the 30-NN average is discontinuous.\"\"\"\n",
    "xgrid = scipy.linspace(0, 1, 1001)\n",
    "y_true = scipy.sin(4*xgrid)\n",
    "\n",
    "size_sample = 100\n",
    "x_sample = scipy.random.uniform(size=size_sample)\n",
    "y_sample = scipy.sin(4*x_sample) + scipy.randn(size_sample)/3\n",
    "\n",
    "idx_x0 = 500\n",
    "x0 = xgrid[idx_x0]  # .5\n",
    "idx_x0_neighbors = scipy.argsort((x_sample-x0)*(x_sample-x0))\n",
    "\n",
    "k = 50\n",
    "y_knn = scipy.array([knn(k, x, x_sample, y_sample) for x in xgrid])\n",
    "\n",
    "fig61 = plt.figure(61, figsize=(10, 5))\n",
    "ax1 = fig61.add_subplot(1, 2, 1)\n",
    "ax1.plot(xgrid, y_true, color='C0', linewidth=2)\n",
    "ax1.plot(xgrid, y_knn, color='C2')\n",
    "ax1.plot(x_sample[idx_x0_neighbors[:k]], y_sample[idx_x0_neighbors[:k]],\n",
    "         'o', color='C3', mfc='none')\n",
    "ax1.plot(x_sample[idx_x0_neighbors[k:]], y_sample[idx_x0_neighbors[k:]],\n",
    "         'o', color='C0', mfc='none')\n",
    "ax1.plot((x0, x0), (ax1.get_ylim()[0], y_knn[idx_x0]), 'o-', color='C3')\n",
    "ax1.set_title('Nearest-Neighbor Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel-weighted average\n",
    "\n",
    "> Rather than give all the points in the neighborhood equal weight, we can assign weights that die off smoothly with distance from the target point.\n",
    "\n",
    "The right panel shows an example of this, using the so-called Nadaraya-Watson kernel-weighted average\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x_0) = \\frac{\\sum_{i=1}^N K_\\lambda(x_0, x_i)y_i}{\\sum_{i=1}^N K_\\lambda(x_0, x_i)},\n",
    "\\end{equation}\n",
    "\n",
    "with the _Epanechnikov_ quadratic kernel\n",
    "\n",
    "\\begin{equation}\n",
    "K_\\lambda(x_0,x) = D \\left( \\frac{|x-x_0|}\\lambda \\right),\n",
    "\\end{equation}\n",
    "\n",
    "with\n",
    "\n",
    "\\begin{equation}\n",
    "D(t) = \\begin{cases}\n",
    "\\frac34 (1-t^2) & \\text{if } |t| \\le 1; \\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FIGURE 6.1. (The right panel) The kernel-weighted average using an Epanechnikov kernel\n",
    "with (half) window width lambda=0.2.\"\"\"\n",
    "def Epanechnikov(lmbda:float, point:float,\n",
    "                 data_x:scipy.ndarray, data_y:scipy.ndarray) -> float:\n",
    "    t = scipy.absolute(data_x-point)/lmbda  # argment for D\n",
    "    k = scipy.where(t <= 1, 0.75*(1-t), 0)\n",
    "    return (k @ data_y).sum()/k.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAE/CAYAAAB4o6baAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4VFX6xz8nyaQQQgIJvYUQSujSFVxAEaWrqNhWcVcUsSwK/BQRRYEF1wKuDdfOqoiCdFAElRUQaUIQA5iE0AkkEAKBJJPk/P6YkpmQMpNMS/J+nmce5t5z77nnTpgz3/ue93yP0lojCIIgCIIgeAY/bzdAEARBEAShOiHiSxAEQRAEwYOI+BIEQRAEQfAgIr4EQRAEQRA8iIgvQRAEQRAEDyLiSxAEQRAEwYOI+BK8ilLqolIqxsFjtVIqtoSyMUqpTa5tnW+ilJqulPrM2+0QhKqEUuonpdSD5Tz3WaXUB+b30ea+KsC1LfRdKvLZVVdEfHkYpVSKUipVKRVqs+9BpdRPXmzWFTgiZpRS/c2dzNtF9m9SSo1x5Dpa65pa6+QKNNUjKKU+UUrNtNlur5Q6qZSa6M12CYKvYu7rLpsfsCyvt7zdLnegtf6n1tqj4sP8+Q602b5TKXVOKdXPk+0QyoeIL+8QAPzD3Rfx0JNXFnCfUiraA9fyCGV9bkqpLsCPwCyt9Wuurl8QqhDDzQ9Yltdj3m5QVUQpdT/wNjBUa73RyXOVUkq0gIeRD9w7vAJMUkpFFFeolGqrlPpeKXVWKXVAKXWHTdlQpdRvSqlMpdRRpdR0mzJLuPvvSqkjwA/m/b2VUluUUhlKqT1Kqf4254xRSiUrpS4opQ4ppe5RSsUB84GrzU+rGaXcSwbwCfBCSQcopf6mlEowP5V9p5RqblNmHUpUSkUqpVaa7227UmpmMdG3gUqpP811va2UUvaXUm8qpc4rpfYrpa63KWiklFph/kwTlVJjbcqmK6UWK6U+U0plAmNKuZeewHrgWa31Wzb7Gymlliilzpg/xydKq9+87yul1ALzZ79PKdXdkfoEobJj7nc2l/J9fcDcZ1ww908P25T1V0odU0pNVEqdNkegH7ApD1JKvaqUOqJMowzzlVIhNuUjlVK7zf1MklLqJpumNTe364JSap1SKsp8jqVvvd9cb5pSaqpNnSWmAiilRilTlKqDeXuE+fueoUzDdXHm/c8opRYXOfcNpdS/y/gsHwJeA27UWm+x2V9av/+TUmqWUmozcAmIMe+bUdz9l1WfUA601vLy4AtIAQYC3wAzzfseBH4yvw8FjgIPYIqQdQXSgPbm8v5AR0zCuROQCtxsLosGNLDAXE8I0BhIB4aYz7nBvF3XfEwm0MZ8fkOb64wBNpVxL/2BY0CDIvVsAsaY398MJAJx5vt5DthiU4cGYs3vvzS/agDtzJ/DpiLHrgIigGbAGeAmm/bmAU8CBmA0cB6oYy7fCLwDBANdzOdeby6bDhjNbfUDQoq510+AdcBZ4K9FyvyAncDzQCAQAyRj6gyLrd+8L9v8d/EHZgNbnajvM2//X5aXvEp7Ye7rSigr6/s6FGgJKKAfJoHQ1VzW33zuS+Zzh5jLa5vL5wErgDpAGLASmG0u62m+zg3m71ljoK257CcgCWht/o7+BMwxl0Wb+5/3zWWdgRwgzlxu/U7aHBuAqR9PpLCPa41ptOAGc9v/z1weCDQ330ct87H+wEmgdymf7xJMvwGdi5SV2O/b3OsRoL25nYYy7t+R+h709v+5yvSSyJf3eB54XClVt8j+YUCK1vpjrXWe1noXpi/YbQBa65+01nu11gVa63hgIabOyZbpWussrfVl4F5gjdZ6jfmc74EdmL5EAAVAB6VUiNb6pNZ6n7M3orU+hSlS9lIxxQ9j6vgStNZ5wD+BLrbRLwCllD8wCnhBa31Ja/0H8Gkx9c3RWmdorY9gGvrrYlN2GpintTZqrRcBB4ChSqmmQF/gaa11ttZ6N/AB8Febc3/RWi8zf0aXS7jV3pg67rVF9vfA1Am9pLXO1aYctveBO8uof5P575IP/BdTh+5ofYJQGVhmjpRYXmNtyor9vgJorVdrrZO0iY2YHnyutTnXCLxkPncNcBFoY46EjwWe1Fqf1VpfwNTnWL47fwc+0lp/b/4uHtda77ep92Ot9UHzd/Qr7PsXgBe11pe11nuAPRR+Z4tjAjAZ6K+1TjTvGw2sNl/fCLyKSehco7U+DOzC9JAGcB1wSWu9tZRr3ABsBfYW2V9Wvw/widZ6n/l3xljG/TtSn+AEIr68hNb6d0xRnGeKFDUHetl2WMA9mKJLKKV6KaV+NA9HnQfGAVFF6jhapL7bi9TXF2iotc7C1BmMA04qpVYrpdoW116lVDNlkzhbzCEvAzcqpYp2Rs2BN2yufRbT02zjIsfVxfQEZtv2o1zJKZv3l4CaNtvHtda2K8UfBhqZX5aO2LbMtg3FXasobwPbge+VUrVt9jcHGhX5jJ8F6jt5L8HKlA/mSH2CUBm4WWsdYfN636aspO8rSqnBSqmtypQmkIHpR962n0s3P8xZsPQFdTFFznfafHe+Ne8HaIopulMSpfUvjpTbMhl4W2t9zGZfI0z3CYDWugBT32Dpi74A7jK/v9u8XRrjMEWqPjALTwsl9vs2xzjTvzpSn+AEIr68ywuYntKKioCNRTqsmlrrR8zlX2AKqTfVWodjijgp7NFF6vtvkfpCtdZzALTW32mtb8D0JdqPKcJStA601ke0TeJs0RvRWqdjCvfPKFJ0FHi4yPVDtE1ugpkzmIYSmtjsa1r0OmXQuEgH1Aw4YX7VUUqFFSk7bnsLDtSfj0kIHwG+U0rVMu8/Chwqco9hWmvbp0JH6rfgSH2CUNkp9vuqlArCFO1/FaivtY4A1nBlP1ccacBlTOkTlu9OuE2fdRTTcKYnGAQ8p5QaZbPvBCYhA5iSVDH1c5a+6Gugv1KqCXALZYuv08D1mKKC79jsL7XfN+Nsn1RWfYITiPjyIuZQ9CLANpl6FdBaKfVXpZTB/OphScrElMNwVmudrUzJ33eXcZnPgOFKqRuVUv5KqWBlSlhtopSqb07+DMWUv3ARk8AAUx5BE6VUoBO39DpwDab8LgvzgSlKqfYASqlwpdTtxXwW+Zjy4KYrpWqYI3D3OXFtgHrAE+bP7HZzO9ZorY8CW4DZ5vvvhGn44XMn68ccnr8dUye/xvzZbQMylVJPK6VCzJ9zB6VUD2frN+Pq+gTBFyn2+4op/ykI8wOZUmowJiFTJuZI0vvAXKVUPQClVGOl1I3mQz4EHlBKXa+U8jOXFRvtdwH7gJuAt5VSI8z7vsKUCnG9UsoATMTU924xt/8MpvypjzE9gCWUdRGt9QlMQ5Q3KaXmmneX2O+X815cXV+1R8SX93kJU+I7AOahsUGYchROYAoDv4ypMwIYD7yklLqAKW/sq9IqNwuPkZiGrc5geoKZjOlv74fpy38C03BgP3P9YJopuQ84pZRKc+RGtNaZwL8wJbpa9i01t/9LZZrp9zswuIQqHgPCzff8X0z5bDmOXNvMr0ArTMJoFnCbOSIHplB+NKZ7XYopt+x7J+q2orXOBW7FlDC/EtOPxXBM+RGHzNf/wHwv5ak/35X1CYIXWansfb6W2pQV+30194FPYOrbzmF6wFzhxDWfxpTEvtXc56wH2gBorbdhSoKfiyl/cyM2kShXY84NGwa8r5QarLU+gCl/6k1M9z0ckx1Hrs1pX2CalFVW1Mv2OkcxCbDblFKzy+j3y3MfLq1PAGU/5C4IvoNS6mWggdb6fm+3RRAE16FMJswPaq37erstguANRLUKPoMy+Zt1UiZ6YhoaXFrWeYIgCIJQmRCnbcGXCMM01NgIUyLpa8Byr7ZIEARBEFyMDDsKgiAIgiB4EBl2FARBEARB8CAivgRBEARBEDyIz+Z8RUVF6ejoaG83QxAED7Jz5840rXXRJbcqJdKHCUL1wpn+y2fFV3R0NDt27PB2MwRB8CBKqcNlH1U5kD5MEKoXzvRfMuwoCIIgCILgQUR8CYIgCIIgeBARX4IgCIIgCB5ExJcgCIIgCIIHEfElCIIgCILgQUR8CYIgCIIgeBARX4IgCIIgCB7EZ32+hEKW7z7O2z8mknj6IrH1avLogFhGdmns7WYJgiCUSeupa8jNL1xDONBfcXDWEC+2SBC8j0S+fJzlu4/z6roDTB/RngMzBzN9RHteXXeA5buPe7tpgiAIpWIRXpGhBtZP6ENkqIHcfE3rqWu83TRB8Coivnyct39M5OVRnbimZRQGfz+uaRnFy6M68faPid5umiAIQqlYhNfOaYOIbRDBzmmDrAJMEKozIr58nMTTF+kRXcduX4/oOiSevuilFgmCIDjOorE9S90WhOqIiC8fJ7ZeTbannLXbtz3lLLH1anqpRYIgCI4z+v1tpW4LQnVExJeP8+iAWJ5eEs+WpDSM+QVsSUrj6SXxPDog1ttNEwRBKJVAf0V6lpFuM9aReCqDbjPWkZ5lJNBfebtpguBVZLajj2OZ1Th9xT7rbMdJg9rIbEdBEHyeg7OG0HrqGtKzjAyctxmQ2Y6CACK+KgUjuzQWsSUIQqVEhJYgXIkMOwqCIAiCIHgQEV+CIAiCIAgeRMSXIAiCIAiCB5GcL0EQBEFwEwkdO4HRWLjDYCBub7z3GiT4BBL5Enya86tWkzx8OAnt2pM8fDjnV632dpMEQRAcwiK8/CIjabF6FX6RkWA0mvYL1RqJfAk+y/lVqzkzbx4NZ86kRreuXNq5i5PPPQdA+LChXm6dIAhCGZiFV5vNmwBos3kTB/r0pSA93csNE7yNRL4EnyX9vfk0nDmT0N69UAYDob170XDmTNLfm+/tpgmCIDhE8wWflrotVE9EfAk+S05SMjW6dbXbV6NbV3KSkr3UIkEQBOc4fN/9pW4L1RMRX4LPEtQyhks7d9ntu7RzF0EtY7zUIkEQBCcwGChIT+dAn75kJyUVDjkaDN5umeBlRHwJPkvkw+M4+dxzZG39FW00krX1V04+9xyRD4/zdtMEQRDKJG5vvFWAHRo6zCq8ZLajIAn3gs9iSapPnTWTnKRkglrGUHfCBEm2F1yKUuojYBhwWmvdoZjy/sBy4JB51zda65c810KhMiNCSygOl4gv6bwEdxE+bKiILcHdfAK8BSwo5ZiftdbDPNMcQRCqOq6KfH2CdF6CIFRCtNb/U0pFe7sdglAexMS1cuKSnC+t9f+As66oSxA8jRi5Cg5wtVJqj1JqrVKqvbcbIwggJq6VGU/mfF2tlNoDnAAmaa33efDaglAsYuQqOMAuoLnW+qJSagiwDGhV3IFKqYeAhwCaNWvmuRYK1RMxca20eGq2o6Xz6gy8ianzugKl1ENKqR1KqR1nzpzxUNOE6owYuQplobXO1FpfNL9fAxiUUlElHPsfrXV3rXX3unXrerSdQvVETFwrJx4RX452XtJxCZ5GjFyFslBKNVBKKfP7npj6TQktCD6BmLhWTjwy7KiUagCkaq21dF6CL2Excg3t3cu6T4xcqxdKqYVAfyBKKXUMeAEwAGit5wO3AY8opfKAy8CdWmvtpeYKlQCPJcHbmLg2X/Aph++7X0xcKwkuiXyZO69fgDZKqWNKqb8rpcYppSxumLcBv5tzvv6NdF5CGXgqCV6MXAWt9V1a64Zaa4PWuonW+kOt9Xyz8EJr/ZbWur3WurPWurfWeou32yz4Lp5MghcT18qLSyJfWuu7yih/C5MVhSCUiSeT4MXIVRDcS+upa8jNL3zWDvRXHJw1xIstcjMeToIXoVU5keWFKgHVzQrB00nw4cOGErNyJXF/7CNm5UoRXoLgIizCKzLUwPoJfYgMNZCbr2k9dY23m+ZWJAleKAsRXz6OJQpUf+pztN2zm/pTn+PMvHlVWoBJErwgVA0swmvntEHENohg57RBVgFWlZEkeKEsRHz5ONXRCsGSBG+LJMELQuVk0diepW5XOWyS4LOTkgqHHCUJXrBBxJePUx2jQJIELwhVh9Hvbyt1u6ohSfCCI3jS4V4oB9XRCkGS4AWhahDor0jPMtJtxjoWje3J6Pe3kZ5lJNBfebtpbrWDEKEllIVEvnwcX44CuXMigCTBC0Ll5+CsIVYBNnDeZqvw8vZsx8qwJmJCx04ktI0rfPlQ24SKI5EvH8dXo0CyJqIgCI7gbaFVLD6+JqKtOLQ1T03o2EmialUEiXxVAnwxCuTrEwGqmz2HIAjO4dN2EDbiMLhlS9ps3mSNzglVAxFfQrnw5YkA1dGeQxAE5/B1OwifFodChRHxJZQLX7aD8PWonCAIXqYS2EH4ujgUKoaIL6Fc+PJEAF+OygmC4H183g6iEohDoWJIwr1QLnx1IgBUT3sOQRCcw2eEVjHE7Y0noWMnqzgEfEscChVGxJdQbsKHDfUJsVUUS1Su6EzMuhMmeLtpgiC4CXf6dnmDytx2oWxEfAlVDl+OygmC4ByOiCqxZhAqG5LzJQBVz5rBF+05BEFwDofNUMWaQahkiPiq4jgiqsSaQRAEn8QJUSXWDEJlQsRXFcZRUSXWDIIg+CqOiiqxZhAqEyK+qjCOiiqxZhAEwVdxSFS52JpB1lUU3I2IryqMo6LKlw1TBUGoxjgoqlzp21UZFt0WKj8y27EK46jflautGc6vWk36e/OtMw0jHx4nCe+CIDhNSX5XAAlt4woPLEFolct+wscX3RaqBhL5qsI46kIfPmwodSdMIHXWTPZ37kLqrJnltmaQ5H1BEFxJ3N544vYnWF+AQ5GpikSwJHlfcDcS+arCOON35SrDVNs8M8CaZ5Y6a6ZEvwRBqDiORqYqEME6fN/91vMs24LgSiTyVcUpzu/KUU+v8nh/SfK+IAjuxtHIVLkiWLKuouABJPJVzbAMCxbN7wLsIlOOHlcUWVdREAR342hkypkIVtH8MFlXUXAnEvmqZjhqP1Fe7y9H88wEQRDKhQORKUteV0F6uskqol37UiNYxeaHma8Vtz9BhJfgciTyVc1wdFiwvMOHsq6iIAjlpfXUNeTma+t2oL/i4KwhdseUNAPSIpBshVRBRgbk50NBQen2Ezb5YXYRMHOCvjvFV1VbEFxwDBFf1QxHhwWdHT4UewlBqPw4In7cfe3IUAOLxvZk9PvbSM8y0nrqmmIFWIkUSbQHrFGv0s5rvuBTO+FWf8ZLnBz/qFsFmCwIXn2RYcdqhqPDgiE9e3HkwQdJiGtH0rBhnJ73RonDh2IvIQiVH1vxs35CHyJDDeTma1pPXeOR61uuvXPaIGIbRLBz2iBrG5x1nC9Pov3h++63E26p054HcMsC3Zb7sdRbkJkpC4JXM0R8VTHKmqHoiKfX+VWrydq4kcgHHySwZQy5Scmkf/ABof36FRvNKpoflpeWBrqAE5MmOTxL0p33LAhC2ZQmfjzForE9r9jud3SX035dTq/zaM4jA6g/4yW7/DBXe3zZRrsAqFXL7n7EU6x6IMOOLmb57uO8/WMiiacvEluvJo8OiGVkl8YeubajMxTL8vSyFVP1JvwDgKytv5I6a2axx9vmh1na0ODFlzj60EPUn/qcQ7MkncU6zJmYBP7+RD74IC2+Ge/wrExBEK6kOPEzcN5mj11/9Pvb2DltkN32y/vXOefXZZOQbzuUV5pVhCWPDKPRNNRoridubzwH+vQt9/0Ul89ll1/WNg4/gwEiI633I55i1QOJfLmQ5buP8+q6A0wf0Z4DMwczfUR7Xl13gOW7j3vk+qXNUHQmOuRssr3t2pCWNqiAAIJaxjg8S9IZbIc5A1vGUG/iRDJXrSLzu3VuuZ4gVHZaT11D9DOrra+ShhJHv7+t1G13EuivSM8y0m3GOhJPZdBtxjrSs4w0ykpzahixvOs8Ws4D01Bji2VLK+TxVZLDvl37ze0sMO8XT7Hqg4gvF/L2j4m8PKoT17SMwuDvxzUto3h5VCfe/jHRI9cvUTQlJjmVk+XsQtu2eWQ5iUno/Dy7/DBXm6zaiszc5EPUufceO8Elpq6CUIijuVwliZ9Af+WRdh6cNcTahoHzNluvrXB+GLHokkSOJq+7coFu2wiXXT6XTfutgi8zE6Bi1xMqFSK+HGT57uMMmruRmCmrGTR3Y7HRrMTTF+kRXcduX4/oOiSevuiRNpYkmpTB4JRnl7NeXbZ5ZGjNqedfsMsjK6/JaknROluRablnW8Elpq6CMyilPlJKnVZK/V5CuVJK/VsplaiUildKdS3uOF/F0VyuksSPp2Y7WtqQMmeo9XVw1hCPO86XV7gVR0kRO9v78atVy1QonmLVCsn5cgDLcOLLozrRI7oO21PO8vQS0xfENp8rtl5Ntqec5ZqWUdZ921POEluvpkfaaRFNRXO+tNHo1DBieby6LHlkliHBgKgotNFobUPdCROcupfS8tdsbTAs91z7nnsIjGlhFYrOXk+o1nwCvAUsKKF8MNDK/OoFvGv+t9LgaC6XJ4WWo5Tl6+XLlOiwbxNds2xXhvsRXIeILwewHU4ErMOJ01fssxNfjw6I5ekl8VeItEmD2niknSWJpvT35ju95E95F9p2lclqaQt024rMWjcOIicxkdOvvQb5+cXO3hSE0tBa/08pFV3KISOBBVprDWxVSkUopRpqrU96pIEuoLhEdnfgLp+w8gqT7Oxsvth+gg0JqZy/bOSSMZ+8Ak3tGoE0qx1Cjxa1uaNrI4KDgyvcxisoJfFfhJbgEvGllPoIGAac1lp3KKZcAW8AQ4BLwBit9a6ix/kqjg4nWoTY9BX7rLMdJw1q47HZjlCyaCouIuau6FB5hZstpSX9FyfwGs2ZI4JLcBeNgaM228fM+yqF+LLN5bI1L3V1LpczJqmuJjs7m8cX7eWng2cwOmCNceTsZfYcO8/Kvad4fkWCXVlokB+juzfh+eEdK9QmRyJ24m5ffXFV5OsTqnDY3pnhxJFdGntUbDlCZVzypyyHfVcIPEFwkOJUSrG/8Eqph4CHAJo1a+bONl1BSVGng7OG0HrqGmsul22ZK7HNLQPYOW2QNWnfHSz77ShPL95Ljot9yLJyCvho8xE+2nwEgFrBAXw5thftGkc4XVdpQsoV7vYi3iovLhFfVT1s76nhRHd6hJVXrBQUaC7k5JF52ciF7DwADP6KAH8/atcwEB5iwBTYdC0l5a9JLpfgBY4BTW22mwAnijtQa/0f4D8A3bt395g7aVlRJ0/lcrnDJ8xWYBQA65r24I1uo0s9J9jgR4dGtRhzTTTDOpfch2ZnZ/PBliMs++0kh89mFRs1y8zOY8ibpnuIDDWwYcJfiAhzwTBlkWWQyvQvK4IsTVS58VTOV6UO23tiONHRpH53obXmyNlL/HYkg91HMziUlsXh9CyOnbtMXkHJvyGB/n7UDQuiRVQobRqE0aZBGF2b1aZl3dAKiTJHo3WypqTgAVYAjymlvsQUsT/vaw+Ono46lYSrc8ssAmNno3a82PVeOpw9xOO7l9Dv2G9sbHIVYApLdmxciwVjejgtioKDg3nsutY8dl1ru/1/HM9gzCfbOX0h125/epaRLrM2oIB/3tyeu3pHV+Duip8NaR2iLIsKijfBu3hKfDkUtvdmyL4s3D2c6GhSvyvJzDby88E0NuxP5X8Hz5B2MbfY48KCAqgVYqBmUABKQV6BxphfwNmLuVzIyeN4xmWOZ1xmU2Ka9Zy6YUH0jonkurZ1uT6uPrWCnZ8WXla0zlFH/9IQ8SYopRYC/YEopdQx4AXAAKC1ng+swZSvmogpZ/UB77S0dFwVdSpv0rw7csty8jWvd7+b/zUx5X/+Vq8N73a8mad+W0SL20cyfWTF8rJKol3jCLZNvcG6fcvbm/jt6HnrtgamLNvHlGX7+FufZuXODytxNqSDVEi8CV7FU+LLobC9t0L24N1lgcBzHmHG/AI2HjjDkl3H2JBwmtz8AmtZVM1AujStzVXNImhdP4zoyBo0rVODYIN/ifVdzs0nNTObP09f5GDqBf44kcmvh85y5kIOK/ecYOWeEwT6+3Ftqyhu7dqEG9rVJzDANfZypc2IdERAuUK8CZUfrfVdZZRr4FEPNafcuCLqVJGkeVfmlt327mZ2HM5gVUE+mxt1tu5vEhHM+/cN5eStH7lNeBXH0kdNSwylpGcyeN5mLhsL+01LfpjTIqwcyyAVpaLiTfAenhJfPh229/aQH7jPI8w2snOxfhM+jRnAqrqmDsJPQc8Wdbi+bT2ua1uP2Ho1nR4qDAn0JzoqlOioUG5oVx8wDWEmnbnIpj/TWPv7KbalnGXD/tNs2H+aqJpBjO7RhHt7N6dheEiF7s3ZZZCKUlHxJgi+gquiThUdvqxobtnLaxN4d2Ph9/dYWD36H91F2IiRzLvLNMxYkbUWbflgzwcsT1qOn58fcbXjeKjzQ8RElG7OHB1Zi4QZgwEYNHcjB1MLH44/2nyEjzcfYdFDvegZE1VSFVYq7F/mAvEmeA9leqirYCU2YXsglSJhe7PVxFvATZjD9lrrHaXV2b17d71jR6mHuIxBczcyfUR7O+GzJSmN6Sv2se7Jfk7XV54oWkkCsCK5ZedXrebk63NZN+TvzD8bRmxqEhN++4rvet9Ci9G3cMtVjalfyw3+NkU4fSGbNfEn+WLbEWtnFejvx6huTXikX0uaRdYoV73Jw4dTf+pzdjMiLQuAx6xcWeb5Ce3a03bPbpRNZ6WNRvZ37kLcH/vK1SahYiildmqtu3u7Ha7Ak30YuMZjK/qZ1ayf0IfYBoUz+xJPZTBw3mZS5rjvgSQlPZMBr/x8RS7Kfzb8i6YXTl+RVO6MSFmYsJAP9n5A2uU0Cigo+wQbFIqOkR35cOCHJXqBFRVhACEGP36bOsA9/mE2yGxH38KZ/stVsx0rddjelUN+5Y2iuTqpP+1iDomvvMErrUewM820fEVk36upOTSOhz56k5b9JpWr3vJQLyyYMX1acP810ew4fI5PtqSwZu9JFm47wlc7jjKqa2MmDmrjtBCs6IzIsuwsBKEy4aoZjY4OX7rKUHXg6xuv6Gu7NYtgyfg+wFCHo0OnLpziHz/9gz/P/YlRlx2pUyhC/ENAQU5+Dvk6/4pjNJr49Hh6LOoBgB94rNdTAAAgAElEQVR+dIjswNsD3yYi2CRQLQ/oXV5cR8Zl03UvGwtoO30DY65u5tbhURFalReXRL7cQWWNfLk6iuYsOXn5vP+/ZN79KYlFXz3FzSPnMPSqpjw2IJZW9cN8JrKTePoi7/yUyPLdJ8gv0NQI9Gdcv5aMvTaGkMCSc8yKUpGE+ZJyvnzdA60qI5Ev71JSzldRYeXocaWxLTmNO/7zq92+mkH+/P7iTQ6dv/X4Vib8NIGsvKxSj1MoQgNCua7pdUzrOc0uGlVW5OiZjc/w7eFvixVmlrqbhzXnneveoWlEU1LSM7nu1Z+xnSDur2DfC9e7PQomeB9n+i8RX7h2yC9mymoOzByMwb8wqdyYX0Cb59aSPNu9P+ib/kzj+eW/k5xm6owWbJpL1JRnaTf0OusxzgzLeYJDaVnMWZvAd/tSAWgUHsyMmztwfVx9j1xfZjv6FiK+vI8jEa3oZ1bb5YYB1tyw0oYni9Zty1t3dSnVk8vC7StvZ//Z/cWWGZSBuDpxzOg7o9T8rStEl78/fhERpQ5pZmdnM+nnSWw6ualEMQYQGRxJ3Uv3s/1APbv9Tw2M5YmBnllqTvAOHh92rOy4csjPG4trZ1zK5YUV+1i+2zSBNKZuKDNGdqBD3yc5M3c2WZGhPmtU2iIqlPf+2p2tyenMWPUH+05k8vdPdzC8cyNeGN6OqJpBbr2+OOULgj2ORq7KsrYoTWgVpax8suzsbK7/5noyjZl2+8MDw3n1L6/Su3Fvh64DRYRXrVr4mRPXCzIz8YuMLNEnKzg4mLdueMtu34xfZrAscRm5BSabnj778rn7p1QiM//FuZqwuFcYq5tdT97Fdry+PpFPfzlsJ1iF6otEvlyMM1E0V9hb/HTgNP+3OJ7TF3IINvjx+HWtGHttjNXOwd2RHVfWn1+g+XjzIV5bd5DLxnwiahiYfUtHBnds6LL2Cr6NRL4qB2VFvkoalixKqMGPLGNBieIrOSOZW1fcekWkaXL3ydzX/r5S21jSkGJC2ziryGqxehXBLVtazUlbrF7FoaHDiNufUHLFJV2vfQd0fr6dqWVOAMwfotjc3p/87IYYM7qRd7Etv0wcTYMIGYasakjky4s4GkUrb2K+rdjJqNuYj5v+hdNNrqJb89q8dntnoqNC7Y53V2Tn/KrVnH7lFfJSUzE0bkyj2f/kfHgAyc/P4NixjVx1zxM0CWviVJ3+fooHr43hxvYNeHbpXn7+M41HPt/FXT2bMm1YO2oEyn9XQfAFyrK2KGpZ0SIqlPSsDOv5wQF+7J852DqTsiinLpxiyNIhdonzBmXgiyFf0DaqbZntK23pHSg0I7X4ZNlul5siwgsgKA8eXaXZHOeP8r9EcINVaL2WAV8sJSjwIl/e/JZD9yNUPSTy5SXKk5hvSRBn8lSe+F0T8Ec8T/72Fel3/Y1bJv4Nfz/Xr7FYlDd2vUHS158w6scclIaf7o7jptihBL/yIf/pfZG0Gnk8sK6ASWMDWDh0IR2iOljPPZt9lpMXTfZupy+dZsEfC6gdXJs72txB74b2wwZaaxb8cphZaxLIzSsgpm4ob951Fe0bhbv9HgXvIZGvykNpuWG2lhVx09bamZJe36YuHz5gGrIsmieWnZ1N/yX97ZLoQwNC+WnUT04lrFuiW7YGpLZL7/hFRlKQmWkVaAVGI2SahzTLadeQ0DauxDJLJK3tK0+jA84RUCsev4AstFYopakRUIN3rn+Hbg26OX1dwXeQyFclwBF7i6LDkrfvWE/sg0/y+JYcLubkERPXmXq3dqT5/Ln4T/57udqhteZE1gnyC/JRKBrVbIS/X+Fsw0vGS0z+32QKdAHRtaL5NuVbnt9SQPL4wfScvYZvwg7wddpB2l9XwAPrCtj18j00XfgFAHetvovaQbWtdZ3LOVdsG+LPxLP+9vWcX7mS03PnkXfyJAENG3LzkxPo9Vg/nlj4GwdTL3LrO1uYM6ojt1zlXERNEATXU1JuWOupawBKXNpo97EMEk9lXBEtG7V8FAczDlqPC/YP5vvbvrdaOjhLiUvvmHO8/CIjKTh3zj7Hy80+Wfsnv8zjn+9k5d6j+NdMxBAWT0D4Hi7lXWLMd2MAaBXRim9GfuO2Ngi+gYgvL1FWYn7RYclfk88yKfkwqbvy0X6aIR0b8PKoTtT0h/2THy93O74++DUzts6wbocaQrm28bXUCqxF060ptFoRz/hTFzkWCWv/UoOcDkHUP2Ok/11zOPT1Qb5rNYHNDc5T0MNIsy9foq//DaTG/sq8ARP45cQvdtcK8g+ifWR7Qg2modF6Neqx9tBaPv3jU/5c9BF5s/8N2TkA5J04wclpz9NwxkuseGwILyzfx6IdR3ly0R72Hsvk2SFtCfB3zTJFgiC4BkeS7G2XHzL4FxDVbjYdP33aWq5QLBu5rEy3+bIoaekdW2d5K64QXf7+kF/MLEh/e+ucN+/pxug/m7D06U0MPHqEpheMnKsRxJpeOazq7c+fGX/S8dOO1PCvwXe3fVdu8Sn4NiK+vMSjA2J5ekl8sYn5YL/QdlZOHp9sOcSdB75nfqdbmTyiC3/rE41Siqytv5bbFDQzN5MZW2dQO6g2k3tMJjM3k8UHF7Pt1Da6782m34aLfDKyFmdbt+E/9Z+k5QszqXvNBNJbzufSzl1EPjyOMy/O4caZM9H5eZxq2NA6mzKm2fVc3+z6Mtvwe/rvFOgCTr72CnWz7ct0djan586j1fDhzBnVkY5Nwnlx5T4+2nyIhJOZvHtvVyJqBJbr3gVBcD25+ZoaBsUlY1npLBpDxC8EN1zBhbzCvc/2fJa74kr17HaMMpbecUd0K27f7yS072AvwPz9idv3+xXHRt56A383Gnmn082sjb6a9umHeHbzAm7clcMT4/3QaC7lX+LaRddSP6Q+6+9Y7/L2Ct5Fcr68SGmzHS1+YWkXc/j7Jzv442QmN6bG8329Duy9pV6FTUGNBUZGrRjFofOHeKD9AzzV/Sm78tKW7ol8eJzVnNSYmkrav9/AePwEAQ3qU2/SZKfacjnvMv879j+aDp6AKu6/olLEJfxh3dyRcpZxn+0i7WIOMXVD+fSBnjStU77liQTfQ3K+KjfRz6y2246JqsF/7r3KGumKqJFPftMZGC81I+fUSAIjfyK0zm6HE+mdwVtL71hyv0qbMWmbk9Zq6hqM+ZpOZxJ5ateXBHy1jOZ1cxmxYgR5ulCZfnLjJ5IT5uNIzlclYWSXxsXObFy++zgBfn60nroWPz9FfoGmRVQog26/l8TV8aTOmmm1dnBUeOXk57AzdSfxZ+L55s9vSL2USoEuIDYilseueuzK40tZtNpyPdt2NHr11XLNqgwJCOHG6Bv5s2Ej8k6cuKI8r659yL17dB1WPt6HBz7ezv5TF7jlnc18NKYHnZpIaF4QvMnfP7Zfhmhwh3q8e28Pus1YB2gMUevIr/sjAIaaB8kPiyfn1K0cmPCRW9rj60vvWHLS/pw1hG4z1lH38FnqXc5ADx/AeeALQwBHl7/GxJ8nAjDmuzG0DG/JspuXebHVgqsQ8eVjWHK9hnZqwNLfTEvvBAX4cX3beszb8CeTRnQh5nnn3emf2/Qc36Z8a92+OfZmwgLDeOKqJwj0v3Lorqx1D11tYVHvyQmcnPY8Ortw7DE7AFZeV4Ot8e8zttNY6/6G4SF8Ne5q3pr6DlctX4rfZ6eJb9qc5v94TAxTBcELjHpnMzuPFFpJhBhg4sBW5tmM2YAfQVEbAagRUIONozZyLCO7xKR8X8DdkTPbnLTPvppEXl4+Z4LD+dugZ+memsDzv35K05GT2Lt3L32+6EOmMZOk80l0+rQT20Zvk+WKKjmSsexjvP1jInd2b8qavacACAsKIDevgAW/HObRupfpOG0cCe3akzx8OOdXrS6jNtiVuos7Vt7Btynf0iysGZ8N+YwNt29gRp8Z/F+P/yM4oPgvsGXR6qytv6KNRrK2/srJ554j8uFxLr1fC+HDh9NwxkuoQJMQDGjUiG33d+OHuDze2v0Wa5LX8O2hb9lyfAsAev06bt+zin2jHmLkiDk8Hz2YlH+96tBnIgiC6xj4+kY74eWv4LIRBs7bRPrl8wQ1Woxf4Gly0q/m59E/8+s9vxIcHFzigt2+gK1PWIvVq/CLjASj0eoTVmFsctIS2ncAo5EAXUCdnAsMOLqTXxt24MVeY8jLM+WPbb57M5O7TwZMi333WNSDxQcWu6YtgleQyJeP8efpi7z2/UEKNNzTqxkvjexAgda0mbqW7p/Po36RRaABa7Rn7aG1nMo6Rae6nehW35QbsObQGv7M+JPu9bsz+9rZNAht4FA7ihtadPeC0+HDh5Px1dcANP/vAloB7Y79zPgN43n658LZUMtGLkO9N59GM2cysVdPCr47wDs/+fN865uZPvdNrpLolyDY4ch6jeWh75wNHMsojFZ/9vfu9G1Vn6n/m8qKQyus+/POXo3xzHCuf2VbsaasPodZeFkiU202b7LzCasoxc64BALr1OYfuxfjpzUbmnXHT2ueWxrPzFs6cV/7+7ij5R30XNQTjebFrS/y+o7X2XLPFpe0SfAsIr58iC9+PYLWoIHx/Vsy+cY2KKX4NSmdZtlnaThzpnUY0NDjKsKnP8vp2a+yp0sY8WfieS/+PQAigiIY1WoUANtObSO6VjQf3/Sx0+3xhXUP+zbuy9pb15Kbn0tiRiITN07k84TPuS0piaU19tPvQiP+76a2xMRvpuaGpQRdSGXndTcR+9TjXm+7IPgCJS3103rqmgoJsH7/+tFOeAHc++F28L9EUP0jBIabbCPW3bqOBmENaD11jZ3NhKsEoLso0SfMRRRd6sgi9g706cvje5ZwLiiMI2H1+OzXo4QY/Jk6rD3BwcHE3x/PkCVDOHrxKBfyLtDx044sH7m8wtYcgmcR8eUjLNx2hGeX7gUgIsRA31ZR5BVotqek8/SSeO7e9y1BV91OfkE+Z7PPMmzpMHJysvg8OZ9HNzwKmHy0xncZz/w981nwxwJr3be1vs3j9+OqNR+VUtZliqJqRBFqCOXrg1/Tq45m1bJ/sabbd0w4240u677l4ODhHF6zgndbDGb6nFdoCSLAhGpP0aV+dk4bZHWWLy8DX9/I4bOX7PaFhB7Fr8m7FFyOJvvEneSd7UvS9Iet5b4stIqjJJ8wV9N8waccuvkW6zBk/RkvcXL8o7zw68e81cX0EP3+phTCggN4YqDJimjNqDXsPbWXu7+7G4CRy0cy4+oZ3Nz6Zre0UXA9Ir58gK+2H2XKNybh9dzQOOqGBdmtDTlhYEsiVsVz78vd2Ne8ME1vUsBgsptsZVrvx7kx+kZqGGpg8DPwtw5/89atAIXLIDUsZYi0PNQKrMXG0RvJzsvmUvg6Jr72Mt+l7Cb419/IzYfobz4mrf9Q9obFMp1beP71N+ku4ksQWDS25xXb5U12H/Hmz3YrcQAYItcTUM/kReUfeojgwFqcu1TLWu6uYU+3UYZPmC1XJOY7yeH77rcbhjw53vQw7W8IoMX9d8PGZABeX59IsMGfh/rFAtCxQUf23r+Xrgu6YtRGpv0yjYycDMZ0HFPutgieQxLuHWT57uMMmruRmCmrGTR3I8t3H3dJvYt3HuPpb0wzaJ4d0pYHr41hZJfGrHuyHy8/cIl2XZbyXdosvu5dwFPrgpkaMILHOozjnzXups+C3cT+4xnuaHMH4UHhGPyu7Bi8Qfp7861DpMpgILR3LxrOnEn6e/MrXHeQfxDhQeE0vPl2mgwaya3b/AjIx+TAf00QjfbvYn7DdPZFtiD4xBH++0tKha8pCJWdosnt5U12v+3dzcQfz7RuPzEsDSggqO4PAHSv2534++P5+qE+1mNshz3XT+hDZKiB3HxtXYbIHSR07ERC27jCl5OJ8nF7460C7NDQYVbhVXS2Y7GJ+c5gI/JaLFtaeL75Wk8PjmPM1c2sh/9z7QEWbk2xq2LXfbsIDTCtGvLartdYmLDQuTYIXkEiXw5QdKkfixs9UKxPl6Ms++04kxfvQWsY3qkRi3ceY87a/VbD1U+SP+FczjkahDYgtH9XGvceStTHn5OTtMw0lOfmBPjyUppHmCu5vG0bzT/4kNRZM8m4qwufGJeR2DKb2xa/wl9uDON4pB9z9t3L/GQDNYMCef7q5+nTuE/ZFQtCFSLQX5GeZaTbjHUVSnZ/5LPt7DhcOKuxQbvX+TjpNH6BEzCe687aB6Za845sxZ0l4mXJ9wr0V0SGGio07FkatoLINmqV0LGTU1YRDh1bTGJ+aQtsF3cNS8TLmk9WRORNH9mRSzn5fLXL9MA/Zdk+mkaG0LdVfesxW+/ZytWfX83FvIv8c9s/iQyKZFDMIIfbYaHSRSgrMSK+HMB2qR+Aa1pG8fKoTkxfsa/c4uuH/alM/NokvIZ1asjuY+euEHcXQhsyuntfpvSaUnjirXe64pbcSlkeYa7CIvIiHx5Hp7mvMv6ev5DaI5wGHy9l/Npcvh3YnrysGqRnwaXae/jywJcivoRqx8FZQyqc7D73uwTW/n7atKFyqNn6JbJ0PrnnulGQG0VO6q1cNycBf5VARA2DVdxZolvhQYolj1xjFX7n3CS8ALfPVCxK0cT8kijJN8wRkfevO7pw2ZjPSrMF0b0f7uCnydcSHVk4tPvLPb/Q47MeZOdnM/HnibxjeIdrm17r8H24a2KGUDwy7OgAiacv0iO6jt2+HtF1rsh7cJQdKWcZ//ku8gs0j/RvycHUC1ZxZ/D3Y/XJuVD3czJPX03t4NquuAWP4oxH2PlVq0kePtzqXZbnRAdpEXnhw4bS8MlJ3Lj0CKMfXYZ/YCCtn3mRaS8u4olOU8k+eRvG3BC2HN/qytsUhErDwVlDSJkz1Ppy5sd01Z7jvPGjKWrtF5xCzTbTUX755JzpT86p24gMDbH+kORrrMLr4Kwh1ihKQEAAsQ0i2DltEJGhBgpcfYNFKG6mortwJBHfFb5hb97TjW7NClfy6P/Kz2Rn28823X7vdgzKlH4y/ofxrEte53D9thMzbP9WZS2ULpSPKhH5WpeyjjOXz7it/qjwMOZs/JqYhoXrbCWfDCAqPITPEz53qq7Tmdl8tDmF/Jr59GpWmybNMvhzYziJ2d9xyLwU2Ork1cTWacOxA/W5KbqDy2YOOkNFrumoR1hxiflHH3rI4TZaRF7DmTOpdeMgAqKirljr8tEBsWRmG/kkoRMqchM7D6fRrXmUw9cQhOrMH8czeGzhbiCfwKj1BEb9iFIQHhjOsbSb7GZRAtZZlLbizl9hN+yZZ1542p0eX56aqVhcYn6xuCgat2R8HztvtbbTN5Ayx75f3XXfLmsS/sSfJzK7YDbDYh2zyHDlxAyhdKqE+PrvH/9l95ndbqvfWKMzH/04iOCGS/CvkUL+pWiyT44iqO5K5mzb43yFkRAM/JELf2wHFTiB2RtXEBBamBM1sP7DZNb3p/bP+1i0YC1f9X6U5A75xNT0544FqxiN+2wUXDFb0RGPMNvEfIDQ3r0IbNGC3COHHb4GlC3ynrmpLbvOxbDfuIm/LXuFD259mB5NXe+J4w2RLAjuIuNCNkPe3IwypBHSeCH+Iaaco4ldJzKm4xii96x26Mc6ooaBC9l5dsOe4EbrCSdmKlaUYnO2SsBVvmGbnrmeDi98y8Uck4ht8cxqDhUjwLr/tzs5BTlM2TyFvII8h2woRr+/zU5M+/IqBJWdKiG+3hn4DvkF+W69xtq9Z/jgf005dPQSLaJq8OCIJgzuOMLh8zMu5XL/x9s5fDaL7s1r89bdXQkO8Gft3jPMO55C6pGHaBQRxPgBzWgUHsILK/5k0qBYvnrlVRZ0GMq/7uxuzQf7v3yNWriOsW76YS9OFDWcOZPUWTNdKiaKS8z3CwtDX84u4YwrcUTkKaWY2L8fY9f9l4KINYxbeZG1975GvVquWxvNXfYaguAtusz6DkPtbQTVWwsqD4MysOu+XXbHlPVjbUn2L5pH5M6olyNJ7K6+ni0lJdy7Mhr3+4s30erZ1RgLTKbccdPWkjBjsN0xO/66w5oDNu2XaUSGRJaaA+aqiRmCYyitfXM8t3v37nrHjh3eboZLyMnL568fbGNbylnaNazFood7ExZssJtFeep8Nq9/f4Bj57JpUCuIKUPiGNmlMf3Gf8jsfwzjmjaFM1u2HEhlyhur2PjO393S3oR27Wm7ZzfK5klRG43s79yFuD/2uew6ycOHU3/qc3aJ+ckjbyb3yGHa/vab3bGuiCqlZV3gxkWjyVEn8CeE8BADSikC/AJ4vf/rdK7b2aX3krX1V1JnzSRmpfMLoVdXlFI7tdbdvd0OV1CZ+7DYl97AEPUDAaHJFBhrcmubgcy4dobdMSUlaBdN5q9uM+gs4ituf0LhvhJmYFZUFLZ4ZjWWTzYmqgY/TBpwxTGWCBhQphN+dftbuRpn+q8qEfnyZbTWPLNkL9tSztKgVjAfjelBWLBJ1BSdRXlr1yZsSUqzm0V5NKwe7dIPAYXiq136IY6G1XNbmz01W9E2Z8sSLco9dAhDkyZ2x7kqqhQVGsaMv0zmhfVfkZmdR5RfCNe0jGBZ0lJ+T/u9QuLLU/YaguBu2rw+lqDG8SiVR25GN/Y8PJ/g4CujxI7OoqwqP94lzVZ0BHdF4xKmX0/b6RsASE67xISFvzHvrqvsjtnx1x10/rQzBRQwcvlIfh79MxHBEcVVV2X+VpUBEV9u5t8bEln623FqBPrz4ZjuNAgv7MQcmUXZItSP9a+8x+CnlVV4rH/lPVpc5b4lg4oTRZZEdldSXM6WoUkTAooYFbpyGHRI7ADahvfglne2kHTKyICo5sBSzuecr9C9eEqwCoK7yMjO4JoFt2Cok05BTj0unRrJoRceL/Wc6vJj7QrvMHcMewYHB7Pm8T4MedMkfpftOUGf2Ehu79HM7rg99++h46cdAbh20bXsvX+vy9siOIdYTbiR5buPM3f9QfwUvHnXVbRvFG5XHluvJttTztrt255ylth6Na3bT4zowtxOt/Ht3I/4vUtXvp37EXM73cYTI7q4rd3hw4ZSd8IEUmfNZH/nLqTOmllsIrurrhWzciVxf+wjZuXKK4QXuD6qFFO3Ju/e25UAP8UHPx8m2C+UFUkreGT9Izyy/hFe/OVFCrRzk+GdsdcQBF9j8YHF9F04AP+gNPIyO3EpZRy/PTXW283yHWxmKwa3bEmbzZusdhG22FpHlMdZvzy0axzB80ML88wmL9lLSnrmFcdtH73d+r7LAvf9fgiOIZEvN7Ej5SyTvzY96Uwb1o7r4+pfccyjA2J5ekn8Feaqkwa1sR5jGX58+8eaJMaMILZeTf5vQGyFnPUdwZFEdk/hjqjSNS2jmHlzB575Zi8X0rrSoNkZMrIzOJdzjk3HN/FI50eoV8PxoV1HZ14Kgq9xz6p72JMWD8qP7FPDMJ67hv/c242IsLInpFSFHCFHhxPLmq1YtB6/yMhyOeuXh79dG8PmxDQ2HDBZLvV/5ecrLCiCg4P54nXN2eB8ojLz2PVKHCG4byKCUDoS+XIDJzIuM+6zneTmF3D/1c15oE+LYo8b2aUxkwa1YfqKfbR5bi3TV+xj0qA2Vwgry1qPybOHsu7Jfm4XXr6Gu6JKd/ZsxkN/iSE7dShHfh/LrF7vM6GraWg1M+fKJ8eyKBrFE+El+Drd/tvNJLwKgrl8eCzGc325t1dzBnVoVOa53liz0dU4Y35adHbiFbMVzfVYKCk65i4+fKAnjWoFWbdbTlltV57QsRMBOfkU1Azlnkl+vH6LHwV5zhm9Cq5DxJeLyTbmM+6znaRdzKVvbBTThrUr9fjqJKyKutmfX7W67JNw7zDo0ze15YZ29Tl/2chD/91JoJ9pyHfzic1sPbkVY4FnOk7BuyilblJKHVBKJSqlnimmfIxS6oxSarf59aA32ukqViWuouOnHcktyEXnhZOV/BT5l1vQtkFNZt7i2I9xlXBEd3A40dY7LDspqdAgtYh3mCed9Ytjy7MDCTA7Q+Rr6DN7Q2Gh+V4HbNhBg/Cm7Gnpx7+H+3lMHAr2iPhyIVprpi79nfhj52laJ4Q377qKAH/5iKFwxmL9qc/Rds9u6k99jjPz5jklwNwRVfL3U8wb3YXW9WuSePoiH288B8CrO15l7LqxrEtxfHkOoXKilPIH3gYGA+2Au5RSxT01LdJadzG/PvBoI11Iny/6MGWzab3Y/Ox6ZCVOQufVIshf8e2Efk7VVZzJamXDEcEUtzfeKsAODR1Wok1EmdExD5A4u7BvPH4+mymLC43ALff27W3fAvBrW0UlkspVClEGLuSTLSks2XWMEIM/793bndqhgd5uks9gO2NRGQzWGYvp7823Oy4vPZ3Lv+91OjpWEUKDAnjvr90JCw7g5z/8GN3wTT69ydRJncw66fbrC16nJ5CotU7WWucCXwIjvdwml7P4wGI6ftqRTKNpSD3gcgcuHXoKMEVvDpQjV6uoqWpldER3VDDF7Y0nbn9C4atorpRZnFkoKTrmCdZP6GN9v3DHMbYlpwH297Z85HI6J2uOR8LsrbMB01By9DOrra/KNIRc2RDx5SJ+SUpn5mqTqd4rt3eiXaNaZZxhYvnu4wyau5GYKasZNHcjy3cfd2cz3YIjw4mOzFg8v2o1xmPHCGzWvFzRsYrQIiqUN+7sglLw4Y9ZnM9oQkhACG/seoOtJwsX5C7v0Kng0zQGjtpsHzPvK8oopVS8UmqxUqppcRUppR5SSu1QSu04c8Z96806S9+FfXlx64vW7f+Le5dzKfdat7c+c73Tddo6oieeyrCu61geR3Sv/eg7OJzoCJbomAVXmKiWl9gGETw1MNa6fcd/fqWgyL0ah97HpG8K+OYaxRcHvqgSOXyVCRFfLuDYuUs8+sUu8gs04/q1ZFinspNVAavD/fQR7TkwczDTR7Tn1XUHKpUAcyv6D6cAACAASURBVHQ40TJj0ZaiMxbT35tPYIsW+NeqVWp0zF1c17Y+Tw5sjdbwj4W/cWuM6cfpxyM/AhUfOhV8luLUQtHRmJVAtNa6E7AeKDaZR2v9H611d61197p167q4mc5jye06n2vysWtasynbR29n2jeFvnbPDm5Dgwjnl9o6OGuIVYANnLe5WHd7R/Dmj76jw4lO1Wd5X1x0zIM8MbANbRsU2hYNHzb7insN8DewuYPJ9CBXX6r8OXyVCJdYTSilbgLeAPyBD7TWc4qUjwFeASyq4q3KnDNhS05ePo9+vouzWbn8pXVdJt/YpuyTzBR1uL+mZRQvj+pk53Dv6zhqgOqIcWtOUjIhXb3rEv/YgFjij51nfUIqP27tQtPmzTiXbcoD89Sal4LHOQbYRrKaACdsD9Bap9tsvg+87IF2lUpZNg/9v+xPek5hs98f+D69G/emxTOFDwudGtfioX6FERJncYWthG3iPsDOaYOsUTRPUJWtFr6d0I82U9eQk68p0PD3u15ny7MD7Y5ZnXGUIcuHQEEQd19n/+Bf3ELpgmuocOSruiWrFmX2mv3sOXaexhEh/PvOLvj7OR5yd8Th3tdx1ADVkRmLQS1jKLhwwe48T7vE+/kpXh/dmZi6oRxIvUDmxSC+P/w91355LdlJSbKEUNVkO9BKKdVCKRUI3AmssD1AKdXQZnMEkIAXKS1adDTjKB0/7WgVXg1rNGTv/Xvp3bg3vf75vTWkF+Sv2H/qgk/k+FSFxH1fxTaX70RmDi+vtf+v2zSiKa0iWuEXeJr3d/5gV1YZc/gqC64YdqwWyarFsTr+JJ9sScHgr3j7nq5E1HAuwd4Rh3tfx5HhRAtlzViMfHgcuYcOkZ+Z6VWX+FrBBt67txshBn9OHr6WLhE34af8OFe/Rpn3KjlhlQ+tdR7wGPAdJlH1ldZ6n1LqJaXUCPNhTyil9iml9gBPAGO801oTJds8GE1RDDNv9HuDdbebZuy+vDaB1Mxca5m2qcfbOT5VIXEfvONw7wi2CfjvbkzmVEa2Xfk3I7/Bv9Zecs7cQKuXp1Q4h08oG1eIryqfrFocyWcu8vQSU7h66pA4ujQtfqHS0rA43G9JSsOYX8CWpDSeXhLPowOcHwbw1o++Kw1Qw4cNxdCkCblHDrt9WaOyaFU/jJk3dyA/qzVbtv2FpqGtWNjLyN6J40q8V8kJq7xorddorVtrrVtqrWeZ9z2vtV5hfj9Fa91ea91Zaz1Aa73fuy2+MjrUqsMSLF26QRnYe/9erou+DoBTGdm8u7EwQvvT5Gsr7NPlqiR5Vybue5PiHO5LMmz1NLENIri3V+HPbu85G6445r933Ulg5A/kXWzDwHmbyp3DJziGK8RXlU1WLYlsYz7jP9/FxZw8hnZsyP3XRJerHkcd7svCmz/6rjZADYiMJKRDR59wiR/VrQl3dG9CTl4BKUndSb2mDZ/0yeXkzBnF3qujdhqC4Apso0NP/fgUu0+cwS8wjU6Rndh1n32E1vbH9q7uTYiONM3GLu9wnyuT5F2VuO91vOxwn9CxkynaZnkVEX0zb+lEZGjhbMwOL3xrV967cW+i6v1JzdjXMNTZCJgio2I54R5ckXBfKZNVwTTb8O0fE0k8fZHYejV51ME1E19Yvo/9py7QIiqUOaM6olT5n9BGdmlc4eR6byeC+9I6kK7mxREd2HP0PAdONqV+5NVsbp/A9Bc+oEFogyuOdfUC4IJQErbRov49t7Im8TA5p27FL+Asnw/73O7Yzi8WGgXXDjEw+7bO1u3R72+zJrpbth3B1UnylU5olUDR9R6LbruC4taiBKzir/mCTzl83/3Friu5c9ogWjyzGg1czMnnkc+28+69Pazlm+/eTJvXx5F3oRMhoSmsHHsPo9/fRnqWkdZT11SZv5Mv4IrIV6VLVoXy2zws3nmMRTuOEhTgx+3dmjDq3S1e9+iSH333ERLoz9v3dKVGoD97Ukwd3u0rb6f/ov7W101LbiLlfIpT+W+CUBEKo0XZLPnxKnJTh+IXmErSC0/YHTdl8R7OXy78of7thUKhVdHhPkmSvxJ3O9yXtBalw8skAb9NLfR0W/v7aXYfPmdXnnNmMEENlhDQbL5YTriRCouvypisCvY2DwZ/P6vNw9s/JpZ4TtKZi0xb9jsAt3ZtzMLtR3zCo6sq/eh7w+G+LGLr1WT2rR3Ju9SSvHPX0i2qH9c1u47rml1HzwY9OX7xOPvP7nfbAuCCUBwv3nuesLiphMU9S3SHz0iaNtGuPPFUBgt3HLNuFzVSrehwnyNJ8tXKMd0TDvcliSwcX1cyIiyYZwcXWiLd/O4W+wN0AP41UgAY+JXJlqKosK5Wf1c34RKfL631GmBNkX3P27yfAkxxxbVchbM2Dzl5+Tyx8DcuG/MZ2aUROw+fq5BHV3mHPIvDEQ+tyoDV4b5FC1os/tp6H4DXhzVHdmnM1uTWLNwWzJ68UFY93pfQoADOZp9lbcpazmafJXzY3QCkzppJTlIyQS1jvDZhQKja/Hz0Z/657Z8A1DLU4oc7frjiGFt/pn8MiCnWSLW8w0i2UbNFY3tah6Zso2a2eWG2x1TV4au4vfF2Q4LucrgvTmQdGjrMqeHNh/rF8uX2oySnXQIgbtpaEmYMtpb7H3sW3WwGqZdTyc7OthPW1e3v6i6qrcO9szYP//r2APtOZNK0Tggzb+5QIY8uVzvbuzrp3Vt42+G+rBmjLwxvR9sGYRxKy+KllX8AEB4Yjp/y41/b/8U7u98hfNhQIh8eR1DLGHKSkkl/b75PRO+EqkNyRjLjfxgPQLB/MJvvvtIEs/3za63vG9QK5Mkb41zaBkeiZhWdTVkZcdThvqzk+NIoa2iz4TtvO1TPD5MGWGfLXTYW8PjnOwGTsM7MCiX7zF/Q2o+Ob06xE9bV8e/qDqqt+HLG5uGnA6f5cNMh/P0Ub9x5FWHBhgp5dJVnyLMsyvLQqgzkJCXjFxZmt89TuWuOzBgNNvjzxp1XERTgx6IdR1kdfxJ/P39m9JlBZEgke87sEbsJwa1kZGcwcrnJRtEPP7bfu/2KY6Ys3kNWbgFgmoq+9dkb3NKWg7OGkDJnqPVVXNTjXJbRbnjqnIdc632ZkvK2HBJg/9/efYdHWWUPHP/eFBhpCT30GJJAgEBUBBURXRAQUFQUdC1YFsS2oj9ZYaMuFlawobvqquguqKtSdKWqCCIKSFVC6CUEpQcQBJKQdn9/TGESZpKp7zszOZ/nycPM5M7MIYQ3J/eee667syidHHjgQc9jGX92KXpu9kF2HjzuSKyLj1zDqa3PU/J7F2KjS8r9+0q9n/+qbfLlaZuHvJNneHxmFgCPXZ3Kha3rA/716IqEzvbBYESHe3ezW562iWiXUJfMgdZZhHGfb2Df8QKua3sdKfEpnCw6Ke0mRNDM2jaLntN7Ou5nDc86Z8zB44Xl6ryci6vNUAbl2lGUmRpNiPCiOL4id2dRApw/f551ts32cf78eVW+nsViKXcAt32p2ppYDyIhfQJ1kl+hVurT5Z4XKU1xzRSQmq9wVVWbh7Iyzf/NzOLIqSIuTWrIqF5tyz0XYPycTY66LU97dNlnzez1YuB61iyQdWHhoOF9ozjw179S4/zz0cXFAa9ds89KVayNA+92jN5xSRuWbstj8dbDPPrpej4ZeQl1a9Rl+f7lnNlVJjtPRcDdNu82Nhy1LmEpFKuHuf5hd6lTP68RlycSX9f7A7NF8Lmr2/KEq6XMLe3T2HPncNotX+Z4zNOdln/u046PVv3C4ZPW0w8ynlnIetuu2O+GfMfF0y+mjDLm7ZzHoORBHtX7iapV6+SrKv9evpvvt+dRv1Ysk4ede26jrz267LNmk4Z05uLEBqzJPcYTn23g8b5nd6DY68IqjrG/bySKGzSQI2+95ehwH+iC9cr6odVsm0Tem29xavEiR7F8nd59XM66KaV48abO9H/9B1bnHuOtJTuJqWH9r6QSW5G/7ifHe4Dr2bvqllgL31304UUUlVl/MDY5rwmLh57bnRzg8omLHd2t4ywxZA7qeM6Yqg7jDrRohaMuzH5fSoPwOVFyy2k50rnPl6c7LVdnXk2i7cD14wXFTJi3icxBHbFYLLSq04pfT/3KuOXjGJQ8iO0TBpCauaDcv2tYNsU1WbVddqzKxn0nmPSV9QSRSUM6kxAXuN8gPVnyDEZdWDgIZof7yma3zuvWnaNTphB34xDarV1D3I1DODplCud16+7ytRrWqcmrQ63NKl9bvIP2da60vsdtg6psNxHoDRciMn2x/QvSp6U7Eq+hqUPdJl4frMhhr9N5fVnj+50zJpBd6T0VXyu2XF1YfK0Atl0IV+7qtvxoSeFuOdKbnZbOrUimLMvl+Enr99OCIWe/P15Y+QLgWb2fqJzMfLlQUFTKnz/9meJSzR2XtKFvx3O7mfurqlkze12Y8wxJ28a12Zl3OuCxhJsT8+Zz9J23HTNUDe8b5VGSZu+H5mpWqmD1KhqOGMGJzz/j8EsvWV93xAhOLV7k9vV6pjRm5BVJvPt9Dm9/exAawYw2B/iLbeepu3YTzok1eN+mRESms7NSGqLzqdlkPjVsR8bOHDiT9o3au3xeYWEhT88527d6wcM9XI4LdFf6qsjylGv2lhT2RAkISEsKf5+fEG/h1q4tHTWDF0xYzO6J1uvW5c0uZ9mBZXy87WPGXRJSXaPClsx8uTDpq63k5J0mpUkdR3G10ZKb1OH1RdvLzZAMvbgV0VGqWs+Q+LObsLImqGd25dD4wQfK7Rht/OADVdZqPd63HZ1a1OPAUesuzXWH1lW581Q2XIiKrIlXGbGNFlC7XSbntfgvRXn9yP/lHrKHZ7tNvAA6PnN2NuzK1EZ0aBHvdqyRu9Qi5szGIEjL3lCuOD7QvcB89cJNXahTMxqwHtDc68UlAPyr778cYx765iEzQos4MvNVwQ878pi6IpeYKMXkYRlYYqNNiePBq5J5fGYWf+nfzlHz9cGPexh1RRJvLtlZbWdI/DnH0v55V7NSR99526NarYpqxETx+i0XMPAfP1B0tAd5Ues4XnicuJpxbs/89HTDhage/vnTPymmMZZWM4itswOAuLg8Co7U57fTcZU+d9jbKxw1VLHRiqn3uF4md4z38SzHqrirJZNEK/xsfKa/o/5rz7F85mXtY1CXFgxNHcqM7TNYun+pyRFGBpn5cnIiv5gxM62/gYzuk0KnFpVf+IJpcEYLSko1M9bsLVcX9kif1Go9Q+LvOZbuZqX8ORqobeM6/HVAGmUlcRSVFdJzek8mrXF/drw/bUpE5JmSPQVdWpvoWruoG1OXNcPWsOK2FcwceWmlz1udc4RVuWfP5dtRRaLj71mO7phRSyaCa8bIs0n8Q5+sB+CpS59yPJb5fabhMUUamfly8tTsjRz8vZALW8eXayvhzMhdailN6zD+uo7lZkhW7DpSrWdIKqvb8kdls2KeuOOSNny5uS9rD9QgLmE5O39zvzHCnzYlIvI8e+mzjN5aimXvS6zwYlZq6LurHLdfG1Z1g85g7VIzupZMBF+3pEZ0aRlH1t4TwNnjhwYmDmR+7nzm7J7DhCsmmBxleJPky2Zu1n7mZO2nVo1oXh2aQUz0uZOCRrd/8KQlRXUTzHMs4wYN9Hl3pVKKyTf1oO/kEk6f2krub3mVjve1TYmIPNenXs9fohZ4VZze5ZmFjtuJDWtx/QWtPHqvYC0Duqolcz5bUoSf2Q9dTtK4+ZRp6/FD42ZlMfGmiczPtS5JvrTqJcZ0H2NylOEropIvX2elDp4o5MkvNgKQOTCNxEa1XY4zepeazJCcy98ZqmBKiLPw3PWdeGJpbQ6d2Ur6tHSzQwoJr1/1On9o/Qezwwhp3sxKvfHtdk4UWGeVFPDdmKuMDNWlYNWSCXNt/ltv2o+3buj4ZO1enujXzrHz8YOtH5iSfBndqy5YIib58nVWSmvNXz7bwImCYq5q15g/dmvtdqwZu9RkhuRc/sxQBdvgjBbM3nQTyw7Up3m8hZsuakmUm8L76iIxLtHsEMKCJz9ACgsLeXnhDsf9H8eae3wQSEuJSGaxWLinR2v+vfwXwN5+4l+OXyzfXv82ozKqrosNFOf6QufvtdTMBWGXgEVM8uXrrNRHK/c4uthPGtLZ7Q41CN4uNel2HllevaEvfSdbyN15hqjkdjxwpRTSi8BIf/ZsW4l+HZqQEF918+dgzxRIx/PI9vS16Uxfs5fTRWVooP9rS8lIyWD9kfW8mfWmoclXJNUXRsxuR19mpXLyTjFhgbU54d9vSKdJvcovZMHYpSbdziNPfK0avHiTtQB68jfb2bz/d5MjEpHg/o/WUGw7mTpGwTt3Xlzlc4zaiSgdzyPbpmevcdzeevAU96W+7Lj/yZZPDI3FyF51wRQxyZd9VspZZbNSJaVlPDoji8LiMm68oAXXpDer8j08ORbIW9X1GKFId2W7JtzWvTXFpZrHZqznTEmp2SGJMHbweCFfbjzsuL/xb54tNzrPFCQnxLPuqb6OBEwIb/xn+EWO27e/v5aU+BQA/r7674bGUbGeMFzrCyNm2dHbnYHvfJ9D1q/HaR5nYfzgcw+gdSfQNVjS7TxyZQ5MY/nOI2w9eJJXv9nOuGvMOS1BhL9LJ55dbnysTzIWi+dnzcpORBEIV6UlkNykjuNn046fR8L51oL7qdlTuSv9Lq9ez5fl8EiqL4yYmS9vZqW2HTzJ64usRasv3tSFehbzDnv1dsZOhI9aNWJ4ZWgGUQqmfJ/DT7/8VvWTgmz2+n30nbyUpHHz6Tt5qSxvh4G+k5di/xFVzxLDn/t412omUmYKhPkWPdYLe5pzsrCUusXWpe9XfnrFq9fxdTk8ko6sipiZL/BsVqqktIwxs7IoKi3j1m6tuTylUaXjg016eUW2i9rUZ0TPJN75PocxM7OY/+eeph1ZZXSfOuG/ZTsOsf3Q2VnwDeP7efX8SJopEKHh58zeZEywzsTu3zmEOu3XoBQ8tuQxXr3qVY9ew5/C+XBMtFyJmJkvT73zfQ4b9p6gRfx5/HWA+8Nq7YI9UxCMOjIRWh69OpW2jWuzK+80k7/ZblocUl8Yfm5/f63jtnPNjaciaaZAhIb4uhaGZDR33C/IvQ+Ab375xqvXiZTCeV9F1MxXVZyXGycN6UzdKpYbjZopkF5ekc0SG83LN3dhyL9WMOWHHPp1SuDC1vUNj0PqC8NLhlMX++TGdbgqLcGn1wn1RCtSmmZWJ6/ccgHzsg9wplRTWng+ZUXxRNU4zuAvBjP7+tkevUZ1b8xbbWa+fFlulJkCESgXtK7PiCuSKNPw+MwsCouN3/0o9YXh441vt3PcqYv9ov/rFZT3Sc1cQOLY+Y4Pow/DlkO5w9c2pwT59O6H0RpyTuRQWFhY5XODdch7OKk2yZe3y40gMwUisB7tk0pykzrk5J3mlYXbDH//YPSpE4FXsYv9kjE9g/I+oZD4SCuM8PbC9bZOAWW1KTrWA4DLZlxW5fNkObyaLDtuP3R2uXHikPQqlxvtgtXRXlRP9uXHG99aznvLdtO/UwIXtWlQ9RPd8PZkBDkrNDw4d7G/Oq0JiQ3rBeV9QqVbuLTCCF+3XpLI5MU7OHyyiKLDA6gRv5bi6DPM2zmPQcmDKn2uN4lWJC5NR/zMV0lpGY/PPLvc2DOlscfPlZkCEWgZreK5r1dbtIYxMzf4vPzo68kIgzNasPDRXuS8MJCFj/aSxCvEOHexj1YwZXjVXez9EQpFz9IKI7ytzrzadiua/F+HAzBu+biAvX4ozNAGQ8QnX74sN9rJTkQRDKP7pJDSpA45R07z8te+LT9KPWLkqdjFfpOHXez9YXbiI7U/kWHBw9Ylx7KCJEpOWTvf373g7oC8dqQuTUd08uXrcqOzUJ8pODFvPjnXXsuWDh3JufZaTsybb3ZIogo1Y6zLj9FRiveX72ZthSJ4T0g9YmAppforpbYppXYqpca6+HxNpdR02+dXKaUSAx2DP13sfREKiY/U/nhvS3pntrRPO/uR3tnskOjQIp6ubeIBKNw/DK2jWJu31qPie0+EwgxtoEVs8uXPcmO4ODFvPnmvvUbTzCdpn7WepplPkvfaa5KAhYEureK574ok6/LjrA0UFHm3/Cg7FwNHKRUNvAlcA3QAblVKdagw7F7gN611MjAZmBTIGJy72Ne1RHvdxd4XoZL4yKHcntuS3hmKi4lq2JDz588jqmFDKC4OiQRs1v3W2S9dWodTWydwOmc0HV99MSCvbfYMbTBEbMG9P8uN3vC26DmQjr7zNs2ef57al3QHoPYl3Wn2/PMcmvA8cYMGGhKD8N0jfVJYtMXawfzlhdt4alDFn/fuyckIAdUN2Km1zgFQSn0KDAY2O40ZDIy33Z4FvKGUUlprv9c+Knaxzx7f39+X9JgkOmHGlni1W74MgHbLl7Gtx+WUHT1qcmBUqMEqo0bD7zhzuB8pT37GjueHlBvnTfF8pJ7SEJEzX4FYbvSEr0XPgXJmVw61Lrqw3GO1LrqQM7tyDHl/4Z+aMdG8cnMG0VGKfy/fzerdni8/Sj1iQLUAfnW6v9f2mMsxWusS4ATQMBBv7k8Xe7P7dAnjtflgWqX3zWKvzbqnR2sgmuLjXbE0n0mJLnGM8aV4PlRmaAMt4ma+yi83tgrqcqNz0TPgKHoeP2eTIT8Ea7ZNIn/dT46ZL4D8dT9Rs21S0N9bBEZ6yzju79WWN5bs5C+zsvjykSs4r4ZnZz96czKCmTO0YcDVr9AVZ7Q8GYNSaiQwEqB169ZVvrFzTUxSo1qVdrGvOGPgiv0HWbj/YBLu7blzuGPmy34/VEwf0Y3khHg+Xb2X/PxkdNkP6NJaTM2eyl3pd/nc3iQSv58jbubr3R+sy43N4yz8dUBaUN/L7KLnhveN4sCTT3J65Sp0cTGnV67iwJNP0vC+UYa8vwiMh3sn065pXXKP5vOSj7sfK2P2DG0Y2Au0crrfEtjvboxSKgaIA86ZqtRav6u17qq17tq4cdW/+FksFnInDuTqtCZ8+/hVbsdVnDFwZp9BsAv3XWCiErGxlB09yrYel1O4a9fZJcfY4KzueMtei7X5uWsAOHNoMFE1DvPy2smOMZFYPO+LiEq+th86yWvf2Jcbqz670V9mFz3HDRpI49GjOTThebZ2yeDQhOdpPHq01HuFGefdj/9Zsfuc7yl/SVuKKq0BUpRS5yulagC3AHMqjJkD2KcYbgK+DUS9l11V/bwqbrd35rz9XkS2tOwNjgRs98BBjsQrLXuD2aGds3u2dmwUurgBUbX2gILHljwGRGbxvC8CknyFwjbtisuNV6QGf3djKDRhjRs0kKS5c0nbvImkuXMl8fJAKLbnsC8/WpuvZnm9+7EyZs/QhjpbDddDwNfAFmCG1nqTUupZpdR1tmHvAw2VUjuBx4BzrnPBVtUMQXWdQahu0rI3kLZ1y9mPEEi84NzarNO2bsGlp9qBjubrnWtCor1JqPC75stpm/bVWKfm1yil5mitnXcKObZpK6VuwbpNe5i/7+3MyOVGOzmuJfzY23M0e/55al10IfnrfuLAk08CmJ64Ptw7mc/W7SX3aD4dnv6KlKaBqc2SY7KqprVeACyo8NjTTrcLgZuNjsvZsCmrHbUyzuy7wOxH8lTHH2QiNLiqzUocO5+iY5dTs9ESmqZ8xKEdtzsSNIiMo4J8EYiCe1O3aYPxy43OvCl6FuYL5fYcX208SBmaKAVlGm7t1pqXbQdwO3+PeVs8L20pwl/F7fbOnH+QQWQWJ4vw9d2Ynlz5ymli41dxtOQIG576Q9AbCIeDQCw7mrpN24zlRhG+Qrk9x5tLdjJ5WAYPXGldtv7gxz08d12ncrVZvhTPS1uK8FdxSceVGtGK3IlSdiBCS2LDelyZ3IaiI1cRbTlA+huPmx1SSAjEzJdp27QBco6c5pdj+R4tNzrPGDSpZ6GgqJQTBdYtrgn1ajJuQJr8QIpwodyew16bdVGb+nyz+RDbDp1k6fa8crVZvrY3kRna8CczWiJcTb2nO23H/UJZgx+JrbeFP037jveGX2l2WKYKxMyXadu0AVKb1mXho1fw9h0XVbrc6Dxj8PLNXcg/U8LJwmLuvzKJD+/tRqmGZ+Zuku33ES6U23PYa7NqxkTz0s2dbbsfc2kRf55jjBTPCyHC0aa/XUvRsR5E1zzM0kPzOXg8MOc+hqtAJF+mb9NuUtdC55bxlY5xnjF4e+ku6p0Xw7gB7Vm85TA9Uxrz+i0Z1KoRI9vvI1wot+dw3j2b1qwegzo3A6CwpMyx+9Hs9iZCCOELi8XCiPRbKclvQ81G33HZqx+aHZKp/E6+wmWbtvOMwc7Dp9j3WyG3dW/jmDG4OLEB+48XyAxCNRCq7Tkq1mZt3v87CfVqknfyjKPwPhTamwghhC/+MiCdshNdQRVTo9FS+k5eanZIpgnI8ULhsE3bebt9cpM65BeV8N9VexwzBmtyj9E8/jxqeXi0ixDBULE2a8Pe49zw1gr+vXw313RKkPYmIiC8PdxYiEDZNnY87f+RQ2zcz+z6ZSXLdrTn8pSmZodluIjqcF8Z5xmDUb3a8ntBCS8s2ErvtCb8sCOPRz5dT35RicwgiJDSuWU8o3olWZuvztpAQVEpgzNasPDRXuS8MJCFj/aSxEt4xZfDjYUIpMe63k1ZUQMszeZy+9TFZodjimqTfDkv6Tw+M4taNWOoa4nlX9/lcMf7q4lW8LdrO8oPMhFy/tw7hdSmddh95DSvLAz82Y+ieql4VJH9aCI5E1IYZeRlV8Hp9qiY37E0+ZrO4782OyTDBWTZMVzIdnsRjuxnP97w1greX76b/p0S6Fphx6MQ3nB1uLG7/mFCBMOm0e/Q/p9DiY3/ifz88/nHokT+3Kf6NH6uNjNfQoSzisuPhcWBO/tRVD9yuLEIBf+59hlKC1pgSZjNayu+mJt6uAAAGy5JREFUpLCw+rSfkORLiDDhvPz48tey/Ch8I4cbi1BxaWIaLaP6o0trc17zWXSYONXskAwjyZcQYcK+/BgdpXh/+W7W7TmnT7EQVap4VJE98ZLdjiIYUjMXkDh2vuOj4saOhSNHcyavNyo6n5pN53LjlP+ZFKmxJPkSIox0bhnPfVfYlh9nyvKj8M32CQPInTjQ8SGJlwgGT3fWbnx0HIWH+hF93q9sKZ7Gqt3bTYrYONWq4D6QnM+JTG5ShwevSpZifmGIR/qk8M3mQ+w4fIpXFm4jc2AHs0MSQlRzrnrHOe+sBVj3VF/HMrczi8XCX3uM4IUfy7A0XcBdXz3Gz3fPwmKxGPp3MJLMfPnA+ZzIbc9fYz0vcuE2ORdSGMJ5+fG9ZbL8KIQwl7sZLnC9s9aVe3omUe9Mb87k9Sam1h4u/OCaoMdtJkm+fOB8TmRsdBSXtW3EpCGd5VxIYZgurWT5UQgRGtz1jgPvdtaue6ovRUd6U3TsUqJrHqHTvy8KatxmkuTLB87nRNpdnNhAzoUUhnqkTwopTeqQI81XhRAmczfD5e3O2i/uv5wzhwZRfKILKrqIjA8yghq3WST58oH9nEhna3KPOc6JFMII9uXHKIUsPwohTOVuhsvbnbUZberTuUV9CvffRMmpVErKSrn4o4uDGrsZJPnygfM5kcWlZazYdYQnPtsg50IKw3VpFc99vdrK8qMQwjSV9Y7zZWftnId7ooilYO/tlBW2pKCkkF6f9jLgb2Ic2e3oA/uuxvFzNjl2Oz7et53sdhRBUdXO2tF9Ulhk2/346jfb+euANBOjFUJUN9snDCA1c4Fjhgvwu3fcz5m9yZiwmPxf7qH2+f/kKMcY+PlA5t84v8rnutp5GWrtVCT58pGcEymMYN9ZO2lIZy5ObMCa3GM88dkG4OwvATVjonnp5i7c+NZypvyQQ7+OCVzUpr6ZYQshqplAJzfxdS3c2rUln6zdS/6e+6md9Cq/nPyFuxbcxdQBU90+z3nn5fQR3Rg2ZTVHTxc7eouFSlImy45ChDBPd9ZmOC8/zsqS5UchRNh74aYuWGKi0CX1OL37IbSOYl3eOsZ8N8btc9ztvCwq1R41fDWKJF9ChIDZ6/fRd/JSksbNp+/kpY6ecd7srH2kt233Y95pXv0m8jtECyEi39bnrf2+dHEj8nPvR2v4as9XvLL6FbfPcbfz0l1SZgZJvoQwWWVNe73ZWWuJtS4/RimY8kMOa3Nl96MQIvx9dG9XAMoKW1Gw93a0hqlbpjJr2yyX493tvPS04asRJPkSwmSVLS16u7M2o1U8o2zLj4/NyOLUmRKD/zZCCBFYl6c0pXuitY619FQnzhzpA8AzK5/hh19/KDfW3c5L8K7ha7BJ8iWEySpbWhyc0YLH+7Zj/JxNtHvyS8bP2VTlztrRfVLp2LwevxzL57m5m4MdvhBCBFVq5gJW5f7muF98pA8lp9oC8MC3D5BzPMfxue0TBrjsLVZZOwwzyG5HIUxmX1q8rG0jx2POS4ve7qytERPFa8MyGPjPZUxf+yt/SGtCv44JAY9bBFc4bJcXItgq7l60t7Io+HUEdVOfheh8Bs8ezJphaxwHcbv7fxLodhj+kJkvIUwWjKa9KU3rMrZ/ewDGfZ5N3skzXj3f3QYAYQx3BxWbtTNLCLNU3L1or/8COLn9abTt95OLp1fdBd+Xhq/BIsmXECbzZWnRE3ddlkiP5IYcO13E2M82oLVnu3oq2wAgjFHZdnkhqhvnwvjLU5rSufnZDUf52/7uuN1lWhdD4/KHJF9ChIDBGS1Y+Ggvcl4YyMJHewWkgW9UlOLlm7tQzxLD4q2H+WT1rx49z90GgBcWbJHZMAOF0s4sIcxUsTB+34mzM/llOoqGR6wJWBllXPjBhYbG5itJvoSIYM3izuP5G9IBeG7eZnKPnK7yOa42ABw8UcjB38/IbJiBQmlnlhBm8aRQPjcviv5xzwJQrItJn5bO8cLjZoXsEUm+hIhw13VpznVdmlNQXMro6espKS2rdLyr3mKvfrOdlvUtVXbaF4ERajuzhDCLu92L2ycMYMbI7o5xM1fW4PXL/uO433N6T15a9ZIZIXtEdjsKUQ08N7gTa3KPsf7X47z13S7+3DvF7Vj7BgDn8yT3/lbAq0PL11O467QfTpRSDYDpQCKQCwzVWv/mYlwpkG27+4vW+rpgxhWMg4qFMJuvO3jdjemW1IjruzTni6z9ANzz/iG2jl9D9+ndKaOMD7Z+wOc7P+fH234MzF8ggGTmS4hqIK5WLC/fbE2eXl+8g/W/up+Sd7UBICHOQkKcpdw4d532w8xYYLHWOgVYbLvvSoHWOsP2EdTEyy6UdmYJ4a9g7eB97dYLaFg71nH/gglLyBqeReeGnQE4VXKK9GnprNy30q/3CTRJvoSoBmav38czczehgNIyzb1T13CysNjt+IobAMZd0z7g7TBCxGBgmu32NOB6E2MRImIFcwfvuqf6Yl+QLyguY9jbK/jvoP/ycb+PHWNGLBpBv5n9/H6vQInYZcfZ6/fx5pKd7Dx8iuQmdXjwquSA7CATItzYW0dMGtKZzi3jGPj6MvYcy+eu/6xm1qjLUKrqOiL7/53xczY5/k8Foh1GCGiqtT4AoLU+oJRq4macRSm1FigBJmqtvzAsQiEihKsdvPZldX9tGd+b9uMXA7Aq9ze++PlXrr8gnezh2fT8tCfHzxxnf/5+0qelU7BjPCUlZ2fyzVjSj8iZL+lTJMRZzq0j6tSM5d93X0zNmCjW7TnOrHV7PX6dYLTDMIJSapFSaqOLj8FevExrrXVX4I/Aa0qptm7ea6RSaq1Sam1eXl5A4hciUgRzB6/FYuGNWzMc90dP38Dxk4UA/HDLD7zQ4wUAik90oZRCasT/aGoD44hMvio7qFiI6qZi64i2jevwzHUdAXh69iZ25YV30XxVtNZ9tNadXHzMBg4ppZoB2P487OY19tv+zAG+Ay5wM+5drXVXrXXXxo0bB+XvI0Q4MmIH76AuLeiZ3NBxP2PC4rOfSx5E9vBsCg/eQM1mn1Gz2Wxu+LonD1+/35QGxhGZfFV2ULEQ1Y2r1hGtG9SiriWGguJSHv74Z86UlJoUnenmAMNtt4cDsysOUErVV0rVtN1uBPQA5MRyIbxQWcuIQPrwT5cQZzlbUXXOjFaZhScvvddx95WfXqGk1ZOAJF9+c/XDJkJ2ZgnhNZdnR36+gScHptG6QS02H/idiV9uNTtMs0wErlZK7QCutt1HKdVVKfWebUwasFYplQUswVrzJcmXEF4yagdv1vh+jgL8olLNFS9+W+7zk+fHkj08m9T4VOuY/Gao2N8Y8dWIoMTjSkQmX8E4qFiIcOXu7MhhF7fmH7deQEyU4j/Lc1m85ZDZoRpOa31Ua91ba51i+/OY7fG1Wus/2W6v0Fqna6272P5839yohRBV2TK+t+P2L8cK+L9PfwbKL39O6v4+0XsmUrD3Dmo0XsjKQytJn5ZO9sFsdy8bMH7tdgzVBoURvDNLCJ8Mzmjh8vs/o1U8Y/q144Uvt/L4zCy+fOSKc/p5CSFEuLFYLCwa3cOxm/Kz9fvp16mpmwbGtbirWwc+3rYegD9+/UcA7mx/J2O6jwlKfEpr39c5lVIvAse01hOVUmOB+lrrJ1yMO6W19mrNr2vXrnrt2rU+xybC05477gSgzYcfmBxJaApGC5WyMs1dU9fw/fY8urapzycjLyE22pxJcaXUOtuuwrAn17DqaUv7NADStm4xORIB8Ma323l54Q7H/fWZvYmv6/4XzMs/uZwTRSfKPZY93LOZMG+uX/5eYaVBoRAGCVYLlagoxeShXUioZ2Htnt+YVH3rv4QQEeahP6TSPbG+437GhMUUFha6Hb/s1mVkD8/mkqaXAKAIznmq/iZf5RoUApU2KFRKrVRKSYImhA+C2UKlYZ2avHmbtf7rvWW7+TL7QAAiFkII800fdVm5I4jSxi+uZLTVlP5TyB6ezYbhG4ISU5U1X0qpRUCCi09levE+rbXW+5VSScC3SqlsrfUuF+81EhgJ0Lp1ay9eXojIF+wWKhe1acC4AWk8N28zY2ZtoF1CXZIau64WkBMkhBDhZN1TfWmXuYAzpRoNtMtcwDY3uy19PQDcG1XOfEmDQiFCgxEtVO7pkciA9AROnSnhgf/+REHRuf2/5AQJIUQ42jZhgGMR8Uyp5qLnFp4zJlgHgFfk77KjNCgUwiBGtFBRSjFpSGeSGtVm68GTPPnFRipuypETJIQQoSY1cwGJY+c7PtwlS84tKI6eLmbQ69+Xew37jNfR08UM+OeKgB4A7szf5EsaFAphEHf9ugK93FfXEstbt1+IJTaKz37ayyerfy33eTlBQggRSryZrbJYLKzPPJuAbTxwkjveW1ku8Xrv9i7lXqPigeCB4FfyJQ0KhTCWUYdbt0+ox99vSAfgb3M2stZpuVNOkBBChBJ74rXuqb4kJ8RXOVsVX9fCjJHdHfd/2HnU8RoAT/xvc7nXCOQB4HYR2eFeCOG/Gy9syd09Eiku1Yz66Cf2Hy8A5AQJIUToqTg7VdVsVbekRrxxa0a5x3qlNCjfAf+GDgABPwAc/OxwL4SIbJkD0th28CQrdh3lvg/XMXPUpXKChBAi5Aybspp1T/U9Z6diauYCtzsVB3VpwbHTZ3h6jrUh7ufrD/F43xT+sXgnR08X86ePsgCTdjsKIaqvmOgo3vzjhbRqcB7Z+04w9rMNaK0NW/4UQoiq2GerEsfOP2epsaqdindelsQjVyU57r+8cAd3X9rGsQQZjMQLJPkSQlShfu0aTLmzK7VqRPPF+v28+32O2SEJIYTD9gkDzlkWrBGtyJ040KOdio/2S+PWri0d999ZlutYagxG4gWSfAkhPNA+oR6vDrXWR0z8aitLtrps6SeEEKawJ0mLRvcgd+JAx31Pdyq+cFOXcw4SKg5wewlnknwJITzSv1MCo/ukoDU8+PFPbNx3wu3Y2ev30XfyUpLGzafv5KXSgFUIYYiKOxM93amYmrkADdRwyoo0cP7Y+YELzokkX0IIjz3SO4UbLmhBflEp905b49gB6Uw64AshzOC8U3HnweNc9NxCj3cq2ltNbP/7QEZcnuh4XAMT5m0KeKySfAkhAM9mq5RSTBySTvfzG3Do9zPc/Z81/F5YXO75j3y6Hq01eSfPSAd8IYRh7LVfR08X0+e15V7XbdmXKDMHdSxXhD8wvXnAY5VWE0IIx2zVpCGduTixAWtyj/HEZxsAztnJWDMmmnfv6MqN/1rOtkMnefC/P3HDBS2YvGg7k4Z05vb3VvH3G9PJ/N9Gx/OlA74Qwgj+FMjb21WAtQj/3WU5FBRDRpv6gQrPQWa+hBBen9cYVyuWqXd3o1GdGvyw4wjj52xi0o3W5yc3qUNMVFS550sHfCFEKLKfCQk42lXYlywLigl4c1U7Sb6EED6d19iqQS3eG34xltgofi8s4bvtecDZDvilZZodh05JB3whREiqeCaknS9Llt6SZUchhOO8xsvaNmL2+n28uWQnOw6fIjYqitnr97ltoprRKp43/3gh905by7vf59Cgdg1G9WoLwLjPs9EQtAPAhRDCH85nQgLkThzoKNLPnTgwqO8tM19CCMds1ctfb+Wlr7dxc9eWtIi3MPKK86vcqdg7rSl3XNIGgIlfbuWjlXtoXLcmSsHrt2RIB3whRMjy9kzIQJGZLyGEIzkaM3MDxaVlzFy7lzH92jM4owWXJTdi/JxNlSZQz13fiYLiUmat28uTX2ykWZyFsde0l6RLCBHSnIvs7feNIDNfQgjAmoCVlJWxfcI15WarPN2p+PLNXRjQKQGAAycKefGrrdLbSwgRsvzpC+YvSb6EEA722i9nnu5UnL1+H9n7TjAw3ZqAHfr9DM/P2yIJmBAiJPnbF8wfsuwohHCw135V7Pf1eN92VT73zSU7mXRTZy5NakjjuZuZuiKX3/KLePGrbbL8KIQISUYkWq5I8iWEcLAnSePnbGLn4VMkN6nj8U5Fe7sKpRR/u7YDpWWaD1fuYZ+LI4iEECLU2FtP2EmrCSGEYQZntPBppsq5XYVSimeu60jN2CiWbssLQpRCCBE4zj2/po/oxrApqzl6upjUzAVBScCk5ksIERD2JcsVu45QXFrGyt1H+XrTQR76gzRXFUKENueeX8kJ8ax7qi8Na8eWmwkLJJn5EkL4xd6UdefhUzSpW5PHZmRx+PdCr5YshRDCbK56fvV5bXlQ3kuSLyGEz9wdyD15WIYkXUIIU3lbw2Vkzy9ZdhRC+MzbA7mFEMIIFc9ttC8hpmYucDne6J5fknwJIXzmy4HcoUQpdbNSapNSqkwp1bWScf2VUtuUUjuVUmONjFEI4T1va7iM7vkly45CCJ8573C087Qpa4jYCNwIvONugFIqGngTuBrYC6xRSs3RWm82JkQhhC+8reEysueXzHwJIXxWcYfjil1HeOKzDTx4VXjscNRab9Fab6tiWDdgp9Y6R2tdBHwKDA5+dEIIf1Ss2TLq3EZPyMyXEMJn/jRlDSMtgF+d7u8FupsUixDCA841XM59u4w4t9ETknwJIfzia1NWoyilFgEJLj6VqbWe7clLuHjMZeGIUmokMBKgdevWHscohAis7RMGkJq5wFHDBcHtWO8tSb6EEAHj3PMruUkdHrwq2fTETGvdx8+X2Au0crrfEtjv5r3eBd4F6Nq1a3C6MwohPBIqiZYrknwJIQLCXc8vwPQEzE9rgBSl1PnAPuAW4I/mhiSECGdScC+ECIhw7PmllLpBKbUXuBSYr5T62vZ4c6XUAgCtdQnwEPA1sAWYobXeZFbMQojwJzNfQoiACMeeX1rr/wH/c/H4fmCA0/0FgOvujEII4SWZ+RJCBIS955ezMOv5JYQQhpDkSwjh1uz1++g7eSlJ4+bTd/JSZq/f53ZsuPf8EkIIo8iyoxDCJW8L6KtJzy8hhPCbX8mXUupmYDyQBnTTWq91M64/8DoQDbyntZ7oz/sKIYLPuYAecBTQj5+zyW1CFeo9v4QQIhT4u+xoPxfte3cDnM5FuwboANyqlOrg5/sKIYIsHAvohRAiHPiVfMm5aEJELimgF0KI4DCi4N7VuWgu1yWUUiOVUmuVUmvz8vIMCE0I4Y4U0AshRHBUWfNl5LlocjSHEKFDCuiFECI4qky+jDwXTQgRWqSAXgghAs+IZUfHuWhKqRpYz0WbY8D7CiGEEEKEHL+SLzkXTQghhBDCO371+ZJz0YQQQgghvCPHC4mQcWLuXAqysshfs4Ydf+jNiblzzQ5JCCE8tqVjp7O326eVuy+EM0m+REg4MXcuB556Gl1UBEDJ/v0ceOppScCEEGFhS8dOUFpa/sHSUknAhEuSfImQcHjya+jCwnKP6cJCDk9+zaSIhBDCCxUTr6oeF9WaJF8iJJQcOODV40IIIUS4kuRLhISYZs28elwIIYQIV5J8iZDQ5NHRKIul3GPKYqHJo6NNikgIIbwQHe3d46Jak+RLhIS4a6+l2XPPEtO8OShFTPPmNHvuWeKuvdbs0IQQokppmzaem2hFR1sfF6ICv/p8CRFIcddeK8mWECJsSaIlPCUzX0IIIYQQBpLkSwghhBDCQJJ8CSGEEEIYSJIvIYQQQggDSfIlhBBCCGEgSb6EEEIIIQwkyZcQQgghhIEk+RJCCCGEMJDSWpsdg0tKqTxgjxdPaQQcCVI4wSRxG0viNp43sbfRWjcOZjBG8fIaFq7/vuEaN4Rv7BK3sYJy/QrZ5MtbSqm1WuuuZsfhLYnbWBK38cI5dqOE69coXOOG8I1d4jZWsOKWZUchhBBCCANJ8iWEEEIIYaBISr7eNTsAH0ncxpK4jRfOsRslXL9G4Ro3hG/sErexghJ3xNR8CSGEEEKEg0ia+RJCCCGECHlhl3wppforpbYppXYqpca6+HxNpdR02+dXKaUSjY/yXB7E/ZhSarNSaoNSarFSqo0ZcVZUVdxO425SSmmlVEjsZvEkbqXUUNvXfJNS6mOjY3TFg++T1kqpJUqpn23fKwPMiLMipdS/lVKHlVIb3XxeKaX+Yft7bVBKXWh0jKFArl/GkuuX8cLxGmbK9UtrHTYfQDSwC0gCagBZQIcKYx4A3rbdvgWYHiZxXwXUst2+P1zito2rC3wPrAS6hkPcQArwM1Dfdr9JmMT9LnC/7XYHINfsuG2xXAFcCGx08/kBwJeAAi4BVpkdc4j++8r1y8C4bePk+mVs7CF3DTPj+hVuM1/dgJ1a6xytdRHwKTC4wpjBwDTb7VlAb6WUMjBGV6qMW2u9RGudb7u7EmhpcIyuePL1BngOeBEoNDK4SngS9wjgTa31bwBa68MGx+iKJ3FroJ7tdhyw38D43NJafw8cq2TIYOADbbUSiFdKNTMmupAh1y9jyfXLeGF5DTPj+hVuyVcL4Fen+3ttj7kco7UuAU4ADQ2Jzj1P4nZ2L9Ys22xVxq2UugBopbWeZ2RgVfDk650KpCqlliulViql+hsWnXuexD0euF0ptRdYADxsTGh+8/b/QCSS65ex5PplvEi9hgX8+hXjVzjGc/UbYMXtmp6MMZrHMSmlbge6Ar2CGpFnKo1bKRUFTAbuMiogD3ny9Y7BOnV/Jdbf0n9QSnXSWh8PcmyV8STuW4GpWutXlFKXAh/a4i4Lfnh+CcX/l0aT65ex5PplvEi9hgX8/2W4zXztBVo53W/JuVOWjjFKqRis05qVTScawZO4UUr1ATKB67TWZwyKrTJVxV0X6AR8p5TKxboWPicEilY9/T6ZrbUu1lrvBrZhvZiZyZO47wVmAGitfwQsWM8eC3Ue/R+IcHL9MpZcv4wXqdewwF+/zC5087IoLgbIAc7nbDFfxwpjHqR8weqMMIn7AqyFiilmx+tN3BXGf0doFKx68vXuD0yz3W6EdUq5YRjE/SVwl+12mu0CoMz+mtviScR9wepAyhesrjY73hD995Xrl4FxVxgv1y9jYg/Ja5jR1y9T/7I+foEGANtt/9EzbY89i/W3LbBm0TOBncBqIMnsmD2MexFwCFhv+5hjdsyexF1hbEhcvDz8eivgVWAzkA3cYnbMHsbdAVhuu6itB/qaHbMtrk+AA0Ax1t8S7wVGAaOcvt5v2v5e2aHyfRKC/75y/TIw7gpj5fplTOwhdw0z4/olHe6FEEIIIQwUbjVfQgghhBBhTZIvIYQQQggDSfIlhBBCCGEgSb6EEEIIIQwkyZcQQgghhIEk+RJCCCGEMJAkX0IIIYQQBpLkSwghhBDCQP8PEVt8LXQZZIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmbda = .2\n",
    "y_knn_weighted = scipy.array([Epanechnikov(lmbda, x, x_sample, y_sample)\n",
    "                              for x in xgrid])\n",
    "\n",
    "mask_neighbor = scipy.absolute(x_sample-x0)/lmbda <= 1\n",
    "\n",
    "ax2 = fig61.add_subplot(1, 2, 2)\n",
    "ax2.plot(xgrid, y_true, color='C0', linewidth=2)\n",
    "ax2.plot(xgrid, y_knn_weighted, color='C2')\n",
    "ax2.plot(x_sample[~mask_neighbor], y_sample[~mask_neighbor], 'o', color='C0', mfc='none')\n",
    "ax2.plot(x_sample[mask_neighbor], y_sample[mask_neighbor],\n",
    "         'o', color='C3', mfc='none')\n",
    "ax2.plot((x0, x0), (ax1.get_ylim()[0], y_knn[idx_x0]), 'o-', color='C3')\n",
    "ax2.set_title('Epanechnikov Kernel')\n",
    "fig61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted function is now continuous, and quite smooth in the right panel. As we move the target from left to right, points enter the neighborhood initially with weight zero, and then their contribution slowly increases (see Exercise 6.1).\n",
    "\n",
    "Note that we used a metric window size $\\lambda=0.2$ for the kernel fit, which does not change as we move the target point $x_0$, while the size of the 30-NN smoothing window adapts to the local density of the $x_i$. One can, however, also use such adaptive neighborhoods with kernels, but we need to use a more general notation.\n",
    "\n",
    "\\begin{equation}\n",
    "K_\\lambda(x_0, x) = D \\left( \\frac{|x-x_0|}{h_\\lambda(x_0)} \\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $h_\\lambda(x_0)$ is a width function (indexed by $\\lambda$) that determines the width of the neighborhood at $x_0$.\n",
    "\n",
    "* The Epanechnikov kernel uses a constant $h_\\lambda(x_0)=\\lambda$.\n",
    "* KNN replaces $\\lambda$ with the neighborhood size $k$, and we have\n",
    "\n",
    "  \\begin{equation}\n",
    "  h_k(x_0) = |x_0 - x_{[k]}|,\n",
    "  \\end{equation}\n",
    "  \n",
    "  where $x_{[k]}$ is the $k$th closest $x_i$ to $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some implications\n",
    "\n",
    "* The smoothing parameter $\\lambda$, which determines the width of the local neighborhood, has to be determined.\n",
    "  * Large $\\lambda$ implies lower variance -- averages over more observations,  \n",
    "  * but higher bias -- we essentially assume the true functionis constant within the window.\n",
    "\n",
    "* Metric window widths (constant $h_\\lambda(x)$) tend to keep the bias of the estimate constant, but the variance is inversely proportional to the local density.  \n",
    "  Nearest-neighbor window width exhibit the oppoite behavior; the variance stays constant and the absolute bias varies inversely with local density.\n",
    "\n",
    "* Issues arise with nearest-neighbors when there are ties in the $x$. With most smoothing techniques one can simply reduce the data set by averaging the $y_i$ at tied values of $X$, and supplementing these new observations at the unique values of $x_i$ with an additional weight $w_i$ (which multiples the kernel weight).\n",
    "\n",
    "* This leaves a more general problem to deal with: Observation wieghts $w_i$.  \n",
    "  Operationally we simply multiply them by the kernel weights before computing the weighted average. With nearest neighborhoods, it is now natural to insist on neighborhoods with a total weight content $k$ (relative to $\\sum w_i$).  \n",
    "  In the event of overflow (the last observation needed in a neighborhood has a weight $w_j$, which causes the sum of weights to exceed the budget $k$), then fractional parts can be used.\n",
    "\n",
    "* Boundary issues arise. The metric neighborhoods tend to contain less points on the boundaries, while the nearest-neighborhoods get wider.\n",
    "\n",
    "* The Epanechnikov kernel has compact support (needed when used with nearest-neighbor window size). Another popular compact kernel is based on the tri-cube function\n",
    "\n",
    "  \\begin{equation}\n",
    "  D(t) = \\begin{cases}\n",
    "  (1-|t|^3)^3 & \\text{ if } |t| \\le 1;\\\\\n",
    "  0 & \\text{otherwise}.\n",
    "  \\end{cases}\n",
    "  \\end{equation}\n",
    "  \n",
    "  This is\n",
    "  * flatter on top (like the nearest-neighbor box) and\n",
    "  * differentiable at the boundary of its support.\n",
    "  \n",
    "  The Gaussian density function $D(t) = \\phi(t)$ is a popular noncompact kernel, with standard deviation playing the role of the window size. See FIGURE 6.2 in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\S$ 6.1.1. Local Linear Regression\n",
    "\n",
    "The smooth kernel fit still has a problems. Locally-weighted averages can be badly biased on the boundaries of the domain, because of the asymmetry of the kernel in that region, as exhibited in FIGURE 6.3 (left panel).\n",
    "\n",
    "By fitting straight lines rather than constants locally, we can remove this bias exactly to first order; see the right panel of FIGURE 6.3. Actually, this bias can be present in the interior of the domain as well, if the $X$ values are not equally spaced (for the same reasons, but usually less severe). Again locally weighted linear regression will make a first-order correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulation\n",
    "\n",
    "Locally weighted regression solves a separate weighted least squares problem at each target point $x_0$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\alpha(x_0),\\beta(x_0)} \\sum_{i=1}^N K_\\lambda(x_0,x_i) \\left( y_i - \\alpha(x_0) - \\beta(x_0)x_i \\right)^2.\n",
    "\\end{equation}\n",
    "\n",
    "The estimate is then\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x_0) = \\hat\\alpha(x_0) + \\hat\\beta(x_0).\n",
    "\\end{equation}\n",
    "\n",
    "Notice that although we fit an entire linear model to the data in the region, we only use it to evaluate the fit at the single point $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix formulation and equivalent kernel\n",
    "\n",
    "Define\n",
    "* the vector-valued function $b(x)^T = (1, x)$,\n",
    "* the $N\\times2$ regression matrix $\\mathbf{B}$ with $i$th row $b(x_i)^T$, and\n",
    "* the $N\\times N$ diagonal matrix $\\mathbf{W}(x_0)$ with $i$th diagonal element $K_\\lambda(x_0,x_i)$.\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}(x_0) &= b(x_0)^T \\left( \\mathbf{B}^T\\mathbf{W}(x_0)\\mathbf{B} \\right)^{-1} \\mathbf{B}^T \\mathbf{W}(x_0) \\mathbf{y} \\\\\n",
    "&= \\sum_{i=1}^N l_i(x_0)y_i.\n",
    "\\end{align}\n",
    "\n",
    "Note that $l_i(x_0)$ do not involve $\\mathbf{y}$ and thus the estimate is _linear_ in $y_i$. These weights $l_i(x_0)$ combine the weighting kernel $K_\\lambda(x_0,\\cdot)$ and the least squares operations, and are sometimes referred to as the _equivalent kernel_.\n",
    "\n",
    "FIGURE 6.4 illustrates the effect of local linear regression on the equivalent kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under construction ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FIGURE 6.4. Equivalent kernel li(x0) for local regression\"\"\"\n",
    "print('Under construction ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic kernel carpentry\n",
    "\n",
    "Historically, the bias in the Nadaraya-Watson and other local average kernel methods were corrected by modifying the kernel. These modifications were based on theoretical asymptotic MSE considerations, and besides being tedious to implement, are only approximate for finite sample sizes.\n",
    "\n",
    "Local linear regression _automatically_ modfies the kernel to correct the bias _exactly_ to first order, a phenomenon dubbed as _automatic kernel carpentry_.\n",
    "\n",
    "Consider the following expansion for $\\text{E}\\hat{f}(x_0)$, using the linearity of local regression and a series expansion of the true function $f$ around $x_0$,\n",
    "\n",
    "\\begin{align}\n",
    "\\text{E}\\hat{f}(x_0) &= \\sum_{i=1}^N l_i(x_0)f(x_i) \\\\\n",
    "&= f(x_0)\\sum_{i=1}^N l_i(x_0) + f'(x_0)\\sum_{i=1}^N (x_i-x_0)l_i(x_0) + \\frac{f''(x_0)}2 \\sum_{i=1}^N \\sum_{i=1}^N (x_i-x_0)^2 l_i(x_0) + R,\n",
    "\\end{align}\n",
    "\n",
    "where the remainder term $R$ involves third- and higher-order derivatives of $f$, and is typically small under suitable smoothness assumptions. It can be shown (Exercise 6.2) that for local linear regression,\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^N l_i(x_0) = 1 \\text{ and } \\sum_{i=1}^N (x_i-x_0)l_i(x_0) = 0.\n",
    "\\end{equation}\n",
    "\n",
    "Hence\n",
    "\n",
    "\\begin{align}\n",
    "\\text{E}\\hat{f}(x_0) &= f(x_0)\\sum_{i=1}^N l_i(x_0) + f'(x_0)\\sum_{i=1}^N (x_i-x_0)l_i(x_0) + \\frac{f''(x_0)}2 \\sum_{i=1}^N \\sum_{i=1}^N (x_i-x_0)^2 l_i(x_0) + R \\\\\n",
    "&= f(x_0) + \\frac{f''(x_0)}2 \\sum_{i=1}^N \\sum_{i=1}^N (x_i-x_0)^2 l_i(x_0) + R,\n",
    "\\end{align}\n",
    "\n",
    "and the bias\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{E}\\hat{f}(x_0) - f(x_0) = \\frac{f''(x_0)}2 \\sum_{i=1}^N \\sum_{i=1}^N (x_i-x_0)^2 l_i(x_0) + R.\n",
    "\\end{equation}\n",
    "\n",
    "We see that it depends only on quadratic and higher-order terms in the expansion of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\S$ 6.1.2. Local Polynomial Regression\n",
    "\n",
    "Why stop at local linear fit? We can fit local polynomial fits of any degree $d$,\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\alpha(x_0),\\beta_j(x_0), j=1,\\cdots,d} \\sum_{i=1}^N K_\\lambda(x_0,x_i) \\left( y_i - \\alpha(x_0) - \\sum_{j=1}^d \\beta_j(x_0)x_i^j \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "with solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x_0) = \\hat\\alpha(x_0) + \\sum_{j=1}^N \\hat\\beta(x_0)x_o^j.\n",
    "\\end{equation}\n",
    "\n",
    "In fact, the expansion shown in the previous section will tell us that the bias will only have components of degree $d+1$ and higher (Exercise 6.2).\n",
    "\n",
    "FIGURE 6.5 illustrates local quadratic regression. Local linear fits tend to be biased in regions of curvature of the true function, a phenomenon referred to as _trimming the hills_ and _filling the valleys_. Local quadratic regression is generally able to correct this bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-variance tradeoff, again\n",
    "\n",
    "There is of course a price to be paid for this bias reduction, and this is increased variance. The fit in the right panel of FIGURE 6.5 is slightly more wiggly, especially in the tails.\n",
    "\n",
    "Assume the model\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = f(x_i) + \\epsilon_i,\n",
    "\\end{equation}\n",
    "\n",
    "with $\\epsilon_i \\sim^{\\text{iid}} (0, \\sigma^2)$. Then\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Var}(\\hat{f}(x_0)) = \\sigma^2 \\|l(x_0)\\|^2,\n",
    "\\end{equation}\n",
    "\n",
    "where $l(x_0)$ is the vector of equivalent kernel weights at $x_0$.\n",
    "\n",
    "It can be shown (Exercise 6.3) that $\\|l(x_0)\\|$ increases with $d$, and so there is a bias-variance tradeoff in selecting the polynomial degree.\n",
    "\n",
    "FIGURE 6.6 illustrates these variance curves for degree zero, one and two local polynomials. To summarize some collected wisdom on this issue:\n",
    "\n",
    "* Local linear fits can help bias dramatically at the boundaries at a modest cost in variance. Local quadratic fits do little at the boundaries for bias, but increase the variance a lot.\n",
    "* Local quadratic fits tend to be most helpful in reducing bias due to curvature in the interior of the domain.\n",
    "* Asymptotic analysis suggest that local polynomials of odd degree dominate those of even degree. This is largely due to the fact that asymptotically the MSE is dominated by boundary effects.\n",
    "\n",
    "While it may be helpful to tinker, and move from local linear fits at the boundary to local quadratic fits in the interior, we do not recommend such strategies. Usually the application will dictate the degree of the fit. For example, if we are interested in extrapolation, then the boundary is of more interest and local linear fits are probably more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.2. Selecting the Width of the Kernel\n",
    "\n",
    "In each of the kernels $K_\\lambda$, $\\lambda$ is a parameter that controls its width:\n",
    "\n",
    "* For the Epanechnikov or tri-cube kernel with metric width, $\\lambda$ is the radius of the support region.\n",
    "* For the Gaussian kernel, $\\lambda$ is the standard deviation.\n",
    "* $\\lambda$ is the number $k$ of nearest neighbors in $k$-nearest neighborhoods, often expressed as a fraction or _span_ $k/N$ of the total training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-variance tradeoff, again and again\n",
    "\n",
    "There is a natural bias-variance tradeoff as we change the width of the averaging window, which is most explicit for local averages:\n",
    "\n",
    "* If the window is narrow, $\\hat{f}(x_0)$ is an average of a small number of $y_i$ close to $x_0$, and its variance will be relatively large -- close to that of an individual $y_i$. The bias will tend to be small, again because each of the $\\text{E}(y_i) = f(x_i)$ should be close to $f(x_0)$.\n",
    "* If the window is wide, the variance of $\\hat{f}(x_0)$ will be small relative to the variance of any $y_i$, because of the effects of averaging. The bias will be higher, because we are now using observations $x_i$ further from $x_0$, and there is no quarantee that $f(x_i)$ will be close to $f(x_0)$.\n",
    "\n",
    "Similar arguments apply to local regression estimates, say local linear:\n",
    "* As the width goes to zero, the estimates approach a piecewise-linear function that interpolates the training data;\n",
    "* as the width gets infinitely large, the fit approaches the global linear least-squares fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discussion in Chapter 5 on selecting the regularization parameter for smoothing splines applies here, and will not be repeated.\n",
    "\n",
    "Local regression smoothers are linear estimators; the smoother matrix in\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\mathbf{f}} = \\mathbf{S}_\\lambda\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "is built up from the equivalent kernels ($\\S$ 6.1.1), and has $ij$th entry $\\{\\mathbf{S}_\\lambda\\}_{ij} = l_i(x_j)$.\n",
    "\n",
    "Leave-one-out cross-validation is particularly simple (Exercise 6.7), as is generalized cross-validation, $C_p$ (Exercise 6.10), and $k$-fold cross-validation. The effective degrees of freedom is again defined as $\\text{trace}(\\mathbf{S}_\\lambda)$, and can be used to calibrate the amount of smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIGURE 6.7 compares the equivalent kernels for a smoothing spline and local linear regression. The local regression smoother has a span of $40%$, which results in $\\text{df} = \\text{trace}(\\mathbf{S}_\\lambda) = 5.86$. The smoothing spline was calibrated to have the same $\\text{df}$, and their equivalent kernels are qualitatively quite similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under construction ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FIGURE 6.7. Equivalent kernels for a local linear regreession smoother and\n",
    "a smoothing spline\"\"\"\n",
    "print('Under construction ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.3. Local Regression in $\\mathbb{R}^p$\n",
    "\n",
    "Kernel smoothing and local regression generalize very naturally to two or more dimensions.\n",
    "\n",
    "* The Nadaraya-Watson kernel smoother fits a constant locally with weights supplied by a $p$-dimensional kernel.\n",
    "* Local linear regression will fit a hyperplane locally in $X$, by weighted least squares, with weights supplied by a $p$-dimensional kernel.  \n",
    "  It is simple to implement and is generally preferred to the local constant fit for its superior performacne on the boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulation\n",
    "\n",
    "Let $b(X)$ be a vector of polynomial terms in $X$ of maximum degree $d$; e.g., with $d=1$ and $p=2$ we get\n",
    "\n",
    "\\begin{equation}\n",
    "b(X) = (1, X_1, X_2);\n",
    "\\end{equation}\n",
    "\n",
    "with $d=2$ we get\n",
    "\n",
    "\\begin{equation}\n",
    "b(X) = (1, X_1, X_2, X_1^2, X_2^2, X_1X_2);\n",
    "\\end{equation}\n",
    "\n",
    "and trivially with $d=0$ we get\n",
    "\n",
    "\\begin{equation}\n",
    "b(X) = 1.\n",
    "\\end{equation}\n",
    "\n",
    "At each $x_0 \\in \\mathbb{R}^p$ solve\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\beta(x_0)} \\sum_{i=1}^N K_\\lambda(x_0,x_i) \\left( y_i - b(x_i)^T\\beta(x_0) \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "to produce the fit\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x_0) = b(x_0)^T \\hat\\beta(x_0).\n",
    "\\end{equation}\n",
    "\n",
    "Typically the kernel will be a radial function, such as the radial Epanechnikov or tri-cube kernel\n",
    "\n",
    "\\begin{equation}\n",
    "K_\\lambda(x_0,x) = D\\left( \\frac{\\|x-x_0\\|}\\lambda \\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\|\\cdot\\|$ is the Euclidean norm.\n",
    "\n",
    "Since the Euclidean norm depends on the units in each coordinate, it makes most sense to standardize each predictor, e.g., to unit standard deviation, prior to smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary problem gets serious with the curse of dimensionality\n",
    "\n",
    "While boundary effects are a problem in 1D smoothing, they are a much bigger problem in two or higher dimensions, since the fraction of points on the boundary is larger. In fact, one of the manifestations of the curse of dimensionality is that the fraction of points close to the boundary increases to one as the dimension grows.\n",
    "\n",
    "Directly modifying the kernel to accommodate two-dimensional boundaries becomes very messy, especially for irregular boundaries.\n",
    "\n",
    "Local polynomial regression seamlessly performs boundary correction to the desired order in any dimensions. FIGURE 6.8 illustrates local linear regression on some measurements from an astronomical study with an unusual predictor design (star-shaped). Here the boundary is extremely irregular, and the fitted surface must also interpolate over regions of increasing data sparsity as we approach the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under construction ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FIGURE 6.8 3D Galaxy data\"\"\"\n",
    "print('Under construction ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local regression becomes less useful in dimensions much higher than two or three. We have discussed in some detail the problems of the dimensionality, e.g., in Chapter 2. It is impossible to simultaneously maintain localness ($\\Rightarrow$ low bias) and a sizeable sample in the neighborhood ($\\Rightarrow$ low variance) as the dimension increases, without the total sample size increasing exponentially in $p$.\n",
    "\n",
    "Visualization of $\\hat{f}(X)$ also becomes difficult in higher dimensions, and this is often one of the primary goals of smoothing. Although the scatter-cloud and wire-frame pictures in FIGURE 6.8 look at attractive, it is quite difficult to interpret the results except at a gross level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a data analysis perspective, conditional plots are far more useful.\n",
    "\n",
    "FIGURE 6.9 shows an analysis of some environmental data with three predictors. The _trellis_ display here show ozone as a function of radiation, conditioned on the other two variables, temperature and wind speed. However, conditioning on the value of a variable really implies loca to that value (as in local regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under construction ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FIGURE 6.9. Conditional plots for Los Angeles Ozone data\"\"\"\n",
    "print('Under construction ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above each of the panels in FIGURE 6.9 is an indication of the range of values present in that panel for each of the conditioning values. In the panel itself the data subsets are displayed (response versus remaining variable), and a 1D local linear regression is fit to the data.\n",
    "\n",
    "Although this is not quite the same as looking at slices of a fitted 3D surface, it is probably more useful in terms of understanding the joint behavior of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.4. Structured Local Regression Models in $\\mathbb{R}^p$\n",
    "\n",
    "> When the dimension to sample-size ratio is unfavorable, local regression does not help us much, unless we are willing to make some structural assumptions about the model.\n",
    ">\n",
    "> Much of this book is about structured regression and classification models. Here we focus on some approaches directly related to kernel methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\S$ 6.4.1. Structured Kernels\n",
    "### Standardization\n",
    "\n",
    "One line of approach is to modify the kernel. The default spherical kernel\n",
    "\n",
    "\\begin{equation}\n",
    "K_\\lambda(x_0,x) = D\\left( \\frac{\\|x-x_0\\|}\\lambda \\right)\n",
    "\\end{equation}\n",
    "\n",
    "gives equal weight to each coordinate, and so a natural default strategy is to standardize each variable to unit standard deviation.\n",
    "\n",
    "A more general approach is to use a positive semidefinite matrix $\\mathbf{A}$ to weigh the different coordinates:\n",
    "\n",
    "\\begin{equation}\n",
    "K_{\\lambda,\\mathbf{A}}(x_0,x) = D \\left( \\frac{(x-x_0)^T\\mathbf{A}(x-x_0)}\\lambda \\right).\n",
    "\\end{equation}\n",
    "\n",
    "Entire coordinates or directions can be downgraded or omitted by imposing appropriate restrictions on $\\mathbf{A}$. For example, if $\\mathbf{A}$ is diagonal, then we can increase or decrease the influence of individual predictors $X_j$ by increasing or decreasing $A_{jj}$.\n",
    "\n",
    "Often the predictors are many and highly correlated, such as those arising from digitized analog signals or images. The covariance function of the predictors can be used to tailor a metric $\\mathbf{A}$ that focuses less, say, on high-freqeuncy contrast (Exercise 6.4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured regression over general models for $\\mathbf{A}$\n",
    "\n",
    "Proposals have been made for learning the parameters for multidimensional kernels. For example, the projection-pursuit regression model discussed in Chapter 11 is of this flavor, where low-rank versions of $\\mathbf{A}$ imply ridge functions for $\\hat{f}(X)$.\n",
    "\n",
    "More general models for $\\mathbf{A}$ are cumbersome, and we favor instead the structured forms for the regression function discussed next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\S$ 6.4.2. Structured Regression Functions\n",
    "\n",
    "We are trying to fit a regression function\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{E}(Y|X) = f(X_1,X_2,\\cdots,X_p)\n",
    "\\end{equation}\n",
    "\n",
    "in $\\mathbb{R}^p$, in which every level of interaction is potentially present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure via ANOVA decomposition\n",
    "It is natural to consider ANOVA decompositions of the form\n",
    "\n",
    "\\begin{equation}\n",
    "f(X_1,X_2,\\cdots,X_p) = \\alpha + \\sum_j g_j(X_j) + \\sum_{k<l} g_{kl}(X_k,X_l) + \\cdots\n",
    "\\end{equation}\n",
    "\n",
    "and then introduce structure by eliminating some of the higher-order terms.\n",
    "\n",
    "Additive models assume only main effect terms:\n",
    "\n",
    "\\begin{equation}\n",
    "f(X) = \\alpha + \\sum_{j=1}^p g_j(X_j);\n",
    "\\end{equation}\n",
    "\n",
    "Second-order models will have terms with interactions of order at most two, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backfitting\n",
    "In Chapter 9, we describe iterative _backfitting_ algorithms for fitting such lower-order interaction models. In the additive model, for example, if all but the $k$th term is assumed known, then we can estimate $g_k$ by local regression of $Y - \\sum_{j\\neq k}g_j(X_j)$ on $X_k$. This is done for each function in turn, repeatedly, until convergence. The important detail is that at any stage, 1D local regression is all that is needed. The same ideas can be used to fit low-dimensional ANOVA decompositions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying coefficients models\n",
    "An important special case of these structured models are the class ofr _varying coefficient models_. Suppose that we divide the $p$ predictors in $X$ into a set $(X_1, X_2, \\cdots, X_q)$ with $q<p$, and the remainder of the variables we collect in the vector $Z$. We then assume the conditionally linear model\n",
    "\n",
    "\\begin{equation}\n",
    "f(X) = \\alpha(Z) + \\beta_1(Z)X_1 + \\cdots + \\beta_q(Z)X_q.\n",
    "\\end{equation}\n",
    "\n",
    "For given $Z$, this is a linear model, but each of the coefficients can vary with $Z$. It is natural to fit such a model by locally weighted least squares:\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\alpha(z_0),\\beta(z_0)} \\sum_{i=1}^N K_\\lambda(z_0,z_i) \\left( y_i - \\alpha(z_0) - x_{i1}\\beta_1(z_0) - \\cdots - x_{qi}\\beta_q(z_0) \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "FIGURE 6.10 illustrates the idea on measurements of the human aorta. A longstanding claim has been that the aorta thickens with $\\textsf{age}$. Here we model the $\\textsf{diameter}$ of the aorta as a linear function of $\\textsf{age}$, but allow the coefficients to vary with $\\textsf{gender}$ and $\\textsf{depth}$ down the aorta. We used a local regression model separately for males and females. Wile aorta clearly does thicken with age at the higher regions of the aorta, the relationship fades with distance down the aorta. FIGURE 6.11 shows the intercept and slope as a function of depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDK whether I have this data...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FIGURE 6.10 and 6.11\"\"\"\n",
    "print('IDK whether I have this data...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.5. Local Likelihood and Other Models\n",
    "\n",
    "The concept of local regression and varying coefficient models is extremely broad: Any parametric model can be made local if the fitting method accommodates observation weights. Here are some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "Associated with each observation $y_i$ is a parameter\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_i = \\theta(x_i) = x_i^T\\beta\n",
    "\\end{equation}\n",
    "\n",
    "linear in the covariate(s) $x_i$, and inference for $\\beta$ is based on the log-likelihood\n",
    "\n",
    "\\begin{equation}\n",
    "l(\\beta) = \\sum_{i=1}^N l(y_i,x_i^T\\beta).\n",
    "\\end{equation}\n",
    "\n",
    "We can model $\\theta(X)$ more flexibly by using the likelihood local to $x_0$ for inference of $\\theta(x_0) = x_0^T\\beta(x_0)$:\n",
    "\n",
    "\\begin{equation}\n",
    "l(\\beta(x_0)) = \\sum_{i=1}^N K_\\lambda(x_0,x_i) l(y_i,x_i^T\\beta(x_0)).\n",
    "\\end{equation}\n",
    "\n",
    "Many likelihood models, in particular the family of  generalized linear models including logistic and log-linear models, involve the covariates in a linear fashion. Local likelihood allows a relaxation from a globally linear model to one that is locally linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "As above, except different variables are associated with $\\theta$ from those used for defining the local likelihood:\n",
    "\n",
    "\\begin{equation}\n",
    "l(\\theta(z_0)) = \\sum_{i=1}^N K_\\lambda(z_0,z_i) l\\left(y_i,\\eta(x_i,\\theta(z_0))\\right).\n",
    "\\end{equation}\n",
    "\n",
    "For example, $\\eta(x,\\theta) = x^T\\theta$ could be a linear model in $x$. This will fit a varying coefficient model $\\theta(z)$ by maximizing the local likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "Autoregressive time series models of order $k$ have the form\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + \\cdots + \\beta_k y_{t-k} + \\epsilon_t.\n",
    "\\end{equation}\n",
    "\n",
    "Denoting the _lag set_ by\n",
    "\n",
    "\\begin{equation}\n",
    "z_t = (y_{t-1}, y_{t-2}, \\cdots, y_{t-k}),\n",
    "\\end{equation}\n",
    "\n",
    "the model looks like a standard linear model\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = z_t^T\\beta + \\epsilon,\n",
    "\\end{equation}\n",
    "\n",
    "and is typically fit by least squares. Fitting by local least squares with a kernel $K(z_0,z_t)$ allows the model to vary according to the short-term history of the series.\n",
    "\n",
    "This is to be distinguished from the more traditional dynamic linear models that vary by windowing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration of local likelihood, we consider the local version of the multiclass linear logistic regression model of Chapter 4. The data consist of features $x_i$ and an associated categorical response $g_i \\in \\{1,2,\\cdots,J\\}$, and the linear model has the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Pr}(G=j|X=x) = \\frac{\\exp\\left(\\beta_{j0} + \\beta_j^Tx\\right)}{1 + \\sum_{k=1}^{J-1} \\exp\\left(\\beta_{k0} + \\beta_k^Tx\\right)}.\n",
    "\\end{equation}\n",
    "\n",
    "The local log-likelihood for this $J$ class model can be written\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^N K_\\lambda(x_0,x_i) \\left\\{ \\beta_{g_i 0}(x_0) + \\beta_{g_i}^T(x_i-x_0) - \\log\\left( 1 + \\sum_{k=1}^{J-1} \\exp\\left( \\beta_{k0}(x_0) + \\beta_k(x_0)^T(x_i-x_0) \\right) \\right) \\right\\}.\n",
    "\\end{equation}\n",
    "\n",
    "Notice that\n",
    "* we have used $g_i$ as a subscript in the first line to pick out the appropriate numerator;\n",
    "* $\\beta_{J0} = 0$ and $\\beta_J = 0$ by the definition of the model;\n",
    "* we have centered the local regressions at $x_0$, so that the fitted posterior probabilities at $x_0$ are simply  \n",
    "\n",
    "  \\begin{equation}\n",
    "  \\hat{\\text{Pr}}(G=j|X=x) = \\frac{\\exp\\left(\\hat\\beta_{j0} + \\hat\\beta_j^Tx\\right)}{1 + \\sum_{k=1}^{J-1} \\exp\\left(\\hat\\beta_{k0} + \\hat\\beta_k^Tx\\right)}.\n",
    "  \\end{equation}\n",
    "  \n",
    "This model can be used for flexible multiclass classification in moderately low dimensions, although successes have been reported with the high-dimensional ZIP-code classficiation problem. Generalized additive models (Chapter 9) using kernel smoothing methods are closely related, and avoid dimensionality problems by assuming an additive structure for the regression function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart disease data, again\n",
    "\n",
    "As a simple illustration we fit a two-class local linear logistic model to the heart disease data of Chapter 4. FIGURE 6.12 shows the univariate local logistic models fit to two of the risk factors (separately). This is a useful screening device for detecting nonlinearities, when the data themselves have little visual information to offer. In this case an unexpected anomaly is uncovered in the data, which may have gone unnoticed with traditional method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under construction ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FIGURE 6.12. Local logistic models for the heart disease data\"\"\"\n",
    "print('Under construction ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\textsf{CHD}$ is a binary indicator, we could estimate the conditional prevalence $\\text{Pr}(G=j|x_0)$ by simply smoothing this binary response directly without resorting to a likelihood formulation. This amounts to fitting a locally constant logistic regression model (Exercise 6.5). In order to enjoy the bias-correction of local-linear smoothing, it is more natural to operate on the unstricted logit scale.\n",
    "\n",
    "Typically with logistic regression, we compute parameter estimates as well as their standard errors. This can be done locally as well, and so we can produce, as shown in the plot, estimated pointwise standard-error bands about our fitted prevalence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.6. Kernel Density Estimation and Classification\n",
    "\n",
    "Kernel density estimation is an unsupervised learning procedure, which historically precredes kernel regression. It also leads to naturally to a simple family of procedures for nonparametric classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\S$ 6.6.1. Kernel Density Estimation\n",
    "\n",
    "### Density estimation\n",
    "\n",
    "> Suppose we have a random sample $x_1,\\cdots,x_N$ drawn from a probability density $f_X(x)$, and we wish to estimate $f_X$ at a point $x_0$.\n",
    "\n",
    "For simplicity assume for now that $X\\in\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local estimate\n",
    "\n",
    "A natural local estimate has the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}_X(x_0) = \\frac{\\#x_i \\in \\mathcal{N}(x_0)}{N\\lambda},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathcal{N}$ is a small metric neighborhood around $x_0$ of width $\\lambda$.\n",
    "\n",
    "This estimate is bumpy, so..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate with kernels\n",
    "\n",
    "the smooth _Parzen_ estimate is preferred.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x_0) = \\frac1{N\\lambda} \\sum_{i=1}^N K_\\lambda(x_0,x_i),\n",
    "\\end{equation}\n",
    "\n",
    "because it counts observations close to $x_0$ with weights that decrease with distance from $x_0$. In this case a popular choice for $K_\\lambda$ is the Gaussian kernel\n",
    "\n",
    "\\begin{equation}\n",
    "K_\\lambda(x_0,x) = \\phi\\left(\\frac{|x-x_0|}\\lambda\\right).\n",
    "\\end{equation}\n",
    "\n",
    "FIGURE 6.13 shows a Gaussian kernel density fit to the sample values for $\\textsf{systolic blood pressure}$ for the $\\textsf{CHD}$ group.\n",
    "\n",
    "Letting $\\phi_\\lambda$ denote the Gaussian density with mean zero and standard-deviation $\\lambda$, the Parzen estimate has the form\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}_X(x) &= \\frac1N \\sum_{i=1}^N \\phi_\\lambda(x-x_i) \\\\\n",
    "&= \\left( \\hat{F}\\star\\phi_\\lambda \\right)(x),\n",
    "\\end{align}\n",
    "\n",
    "the convolution of the sample empirical distribution $\\hat{F}$ with $\\phi_\\lambda$. The distribution $\\hat{F}(x)$ puts mass $1/N$ at each of the observed $x_i$, and is jumpy; in $\\hat{f}_X(x)$ we have smoothed $\\hat{F}$ by adding independent Gaussian noise to each observation $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution = local averaging\n",
    "\n",
    "The Parzen density estimate is the equivalent of the local average, and improvements have been proposed along the lines of local regression [on the log scale for densities; see Loader (1999)]. We will not pursue these here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In $\\mathbb{R}^p$\n",
    "\n",
    "The natural generalization of the Gaussian density estimate amounts to using the Gaussian product kernel,\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{f}(x_0) = \\frac1{N(2\\lambda^2\\pi)^{\\frac{p}2}} \\sum_{i=1}^N \\exp \\left\\{ -\\frac12 \\left( \\|x_i-x_0\\|/\\lambda \\right)^2 \\right\\}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\S$ 6.6.2. Kernel Density Classification\n",
    "\n",
    "One can use nonparametric density estimates for classification in a straight-forward fashion using Bayes' theorem.\n",
    "\n",
    "Suppose for a $J$ class problem\n",
    "* we fit nonparametric density estimates $\\hat{f}_j(X)$, for $j=1,\\cdots,J$ separately in each of the classes,\n",
    "* and we also have estimates of the class priors $\\hat\\pi_j$ (usually the sample proportions).\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\text{Pr}}(G=j|X=x_0) = \\frac{\\hat\\pi_j \\hat{f}_j(x_0)}{\\sum_{k=1}^J \\hat\\pi_k \\hat{f}_k(x_0)}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulty with sparse data\n",
    "\n",
    "FIGURE 6.14 uses this method to estimate to prevalence of $\\textsf{CHD}$ for the heart risk factor study, and should be compared with the left panel of FIGURE 6.12. The main difference occurs in the region of high SBP in the right panel of FIGURE 6.14. In this region the data are sparse for both classes, and since the Gaussian kernel density estimates use metric kernels, the density estimates are low and of poor quality (high variance) in these region.\n",
    "\n",
    "The local logistic regression method uses the tri-cube kernel with $k$-NN of the local linear assumption to smooth out the estimate (on the logit scale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If classification is the ultimate goal, then learning the separate class densities well may be unnecessary, and can in fact be misleading.\n",
    "\n",
    "FIGURE 6.15 shows an example where the densities are both multimodal, but the posterior ratio is quite smooth. In learning the separate densities from data, one might decide to settle for a rougher, high-variance fit to capture these features, which are irrelevant for the purposes of estimating the posterior probabilities. In fact, if classification is the ultimate goal, then we need only to estimate the posterior well near the decision boundary. e.g., for two classes, this is the set\n",
    "\n",
    "\\begin{equation}\n",
    "\\{ x| \\text{Pr}(G=1|X=x) = \\frac12 \\}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\S$ 6.6.3. The Naive Bayes Classifier\n",
    "\n",
    "This is a technique that has remained popular over the years, despite its name (a.k.a. \"Idiot's Bayes\"). It is espeically appropriate when the dimension $p$ of the feature space is high, making density estimation unattractive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive assumption\n",
    "\n",
    "The naive Bayes model assumes that given a class $G=j$, the features $X_k$ are independent:\n",
    "\n",
    "\\begin{equation}\n",
    "f_j(X) = \\prod_{k=1}^p f_{jk}(X_k)\n",
    "\\end{equation}\n",
    "\n",
    "While this assumption is generally not true, it does simplify the estimation dramatically:\n",
    "\n",
    "* The individual class-conditional marginal densities $f_{jk}$ can each be estimated separately using 1D kernel density estimates. This is in fact a generalization fo the original naive Bayes procedures, which used univariate Gaussians to represent these marginals.\n",
    "* If a component $X_j$ of $X$ is discrete, then an appropriate histogram estimate can be used. This provides a seamless wway of mixing variable types in a feature vector.\n",
    "\n",
    "Despite these rather optimistic assumptions, naive Bayes classifiers often outperform far more sophisticated alternatives. The reasons are related to FIGURE 6.15: Although the individual class density estimates may be biased, this bias might not hurt the posterior probabilities as much, especially near the decision regions. In fact, the problem may be able to withstand considerable bias for the savings in variance such a \"naive\" assumption earns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulation\n",
    "\n",
    "Starting from the independence assumption, we can derive the logit-transform (using class $J$ as the base):\n",
    "\n",
    "\\begin{align}\n",
    "\\log\\frac{\\text{Pr}(G=l|X)}{\\text{Pr}(G=J|X)} &= \\log\\frac{\\pi_l f_l(X)}{\\pi_J f_J(X)}\\\\\n",
    "&= \\log\\frac{\\pi_l \\prod_{k=1}^p f_{lk}(X_k)}{\\pi_J \\prod_{k=1}^p f_{Jk}(X_k)}\\\\\n",
    "&= \\log\\frac{\\pi_l}{\\pi_J} + \\sum_{k=1}^p \\log\\frac{f_{lk}(X_k)}{f_{Jk}(X_k)}\\\\\n",
    "&= \\alpha_l + \\sum_{k=1}^p g_{lk}(X_k).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity with generalized additive model\n",
    "\n",
    "This has the form of a _generalized additive model_ (Chapter 9). The models are fit in quite different ways though (Exercise 6.9). The relationship between naive Bayes and generalized additive models is analogous to that between LDA and logistic regression ($\\S$ 4.4.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.7. Radial Basis Functions and Kernels\n",
    "### Review on basis expansion\n",
    "\n",
    "In Chapter 5, functions are represented as expansions in basis functions:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = \\sum_{j=1}^M \\beta_j h_j(x).\n",
    "\\end{equation}\n",
    "\n",
    "The art of flexible modeling using basis expansions consists of picking an appropriate family of basis functions, and then controlling the complexity of the representation by selection, regularization, or both.\n",
    "\n",
    "Some of the families of basis functions have elements that are defined locally; e.g., B-splines. If more flexibility is desired in a particular region, then that region needs to be represented by more basis functions (which in the case of B-splines translates to more knots).\n",
    "\n",
    "Tensor products of $\\mathbb{R}$-local basis functions deliver basis functions local in $\\mathbb{R}^p$. Not all basis functions are local -- e.g., the truncated power bases for splines, or  sigmoidal basis functions $\\sigma(\\alpha_0 + \\alpha x)$ used in neural-networks (Chapter 11).\n",
    "\n",
    "The composed function $f(x)$ can nevertheless show local behavior, because of the particular signs and values of the coefficients causing cancellations of global effects. For example, the truncated power basis has an equivalent B-spline basis for the same space of functions; the cancellation is exact in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review on kernel smoothing\n",
    "\n",
    "Kernel methods achieve flexibility by fitting simple models in a region local to the target point $x_0$. Localization is achieved via a weighting kernel $K_\\lambda$, and individual observations receive weights $K_\\lambda(x_0,x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial basis functions\n",
    "\n",
    "Radial basis functions combine these ideas, by treating the kernel functions $K_\\lambda(\\xi,x)$ as basis functions. This leads to the model\n",
    "\n",
    "\\begin{align}\n",
    "f(x) &= \\sum_{j=1}^M K_{\\lambda_i}(\\xi_j,x)\\beta_j \\\\\n",
    "&= \\sum_{j=1}^N D\\left( \\frac{\\|x-\\xi_j\\|}{\\lambda_j} \\right)\\beta_j,\n",
    "\\end{align}\n",
    "\n",
    "where each basis element is indexed by a location or _prototype_ parameter $xi_j$ and a scale parameter $\\lambda_j$. A popular choice for $D$ is the standard Gaussian density function.\n",
    "\n",
    "There are several approaches to learning the parameters $\\{\\lambda_j, \\xi_j, \\beta_j\\}$, for $j=1,\\cdots,M$. For simplicity we will focus on least squares methods for regression, and use the Gaussian kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  \n",
    "Optimize the sum-of-squares w.r.t. all the parameters,\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\{\\lambda_j,\\xi_j,\\beta_j\\}_1^M} \\sum_{i=1}^N \\left( y_i - \\beta_0 - \\sum_{j=1}^M \\beta_j \\exp\\left( -\\frac{(x_i-\\xi_j)^T(x_i-\\xi_j)}{\\lambda_j^2} \\right)\\right)^2.\n",
    "\\end{equation}\n",
    "\n",
    "This model is commonly referred to as an RBF network, an alternative to the sigmoidal neural network; the $\\xi_j$ and $\\lambda_j$ playing the role of the weights. This criterion is nonconvex with multiple local minima, and the algorithms for optimization are similar to those used for neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  \n",
    "Estimate the $\\{\\lambda_j,\\xi_j\\}$ separately from the $\\beta_j$. Given $\\{\\lambda_j,\\xi_j\\}$, the estimation of $\\beta_j$ is a simple least squares problem.\n",
    "\n",
    "Often the kernel parameters $\\lambda_j$ and $\\xi_j$ are chosen in an unsupervised way using the $X$ distribution alone. One of the methods is to fit a Gaussian mixture density model to the training $x_i$, which provides both the centers $\\xi_j$ and the scales $\\lambda_j$.\n",
    "\n",
    "Other even more adhoc approaches use clustering methods to local the prototypes $\\xi_j$, and treat $\\lambda_j = \\lambda$ as a hyper-parameter. The obvious drawback of these approaches is that the conditional distribution $\\text{Pr}(Y|X)$ and in particular $\\text{E}(Y|X)$ is having no say in where the action is concentrated.\n",
    "\n",
    "On the positive side, they are much simpler to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renormalize\n",
    "\n",
    "While it would seem attractive to reduce the parameter set and assume a constant value for $\\lambda_j=\\lambda$, this can have an undesirable side effect of creating _holes_ -- regions of $\\mathbb{R}^p$ where none of the kernels has appreciable support, as illustrated in FIGURE 6.16 upper panel. _Renormalized_ radial basis functions,\n",
    "\n",
    "\\begin{equation}\n",
    "h_j(x) = \\frac{D(\\|x-\\xi_j\\|/\\lambda)}{\\sum_{k=1}^M D(\\|x-\\xi_k\\|/\\lambda)}\n",
    "\\end{equation}\n",
    "\n",
    "avoid this problem (FIGURE 6.16 lower panel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nadaraya-Watson kernel regression estimator in $\\mathbb{R}^p$ can be viewed as an expansion in renormalized radial basis functions,\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}(x_0) &= \\sum_{i=1}^N y_i \\frac{K_\\lambda(x_0,x_i)}{\\sum_{j=1}^N K_\\lambda(x_0,x_j)} \\\\\n",
    "&= \\sum_{i=1}^N y_i h_i(x_0),\n",
    "\\end{align}\n",
    "\n",
    "with a basis function $h_i$ located at every observation and coefficients $y_i$; i.e.,\n",
    "\n",
    "\\begin{align}\n",
    "\\xi_i &= x_i, \\\\\n",
    "\\hat\\beta_i &= y_i, \\text{ for } i=1,\\cdots,N.\n",
    "\\end{align}\n",
    "\n",
    "Note the similarity between the expansion and the solution (5.50 on page 169) to the regularization problem induced by the kernel $K$. Radial basis functions form the bridge between the modern \"kernel methods\" and local fitting technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.8. Mixture Models for Density Estimation and Classification\n",
    "\n",
    "The mixture model is a useful tool for density estimation, and can be viewed as a kind of kernel method. The  Gaussian mixture model has the form\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = \\sum_{m=1}^M \\alpha_m\\phi(x;\\mu_m,\\mathbf{\\Sigma}_m)\n",
    "\\end{equation}\n",
    "\n",
    "with mixing proportions $\\sum\\alpha_m=1$.\n",
    "\n",
    "In general, mixture models can use any component densities in place of the Gaussian: The Gaussian mixture model is by far the most popular.\n",
    "\n",
    "The parameters are usually fit by maximum likelihood, using the EM algorithm as described in Chapter 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some special cases arise\n",
    "\n",
    "* If the covariance matrices are constrained to be scalar: $\\mathbf{\\Sigma}_m=\\sigma_m\\mathbf{I}$, then it has the form of a radial basis expansion.\n",
    "* If in addition $\\sigma_m = \\sigma >0$ is fixed, and $M\\uparrow N$, then the maximum likelihood estimate approaches the kernel density estimate  \n",
    "\n",
    "  \\begin{equation}\n",
    "  \\hat{f}_X(x_0) = \\frac1{N\\lambda} \\sum_{i=1}^N K_\\lambda(x_0,x)\n",
    "  \\end{equation}\n",
    "  \n",
    "  where $\\hat\\alpha_m = 1/N$ and $\\hat\\mu_m = x_m$.\n",
    "\n",
    "Using Bayes' theorem, separate mixture densities in each class lead to flexible models for $\\text{Pr}(G|X)$ (Chapter 12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart disease, again\n",
    "\n",
    "FIGURE 6.17 shows an application of mixtures to the heart disease risk factor study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\S$ 6.9. Computational Considerations\n",
    "\n",
    "Kernel and local regression and density estimation are _memory-based_ methods: The model is the entire training data set, and the fitting is done at evaluation or prediction time. For many real-time applications, this can make this class of methods infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational cost to fit at a single obervation $x_0$ is $O(N)$ flops, except in oversimplified cases (such as square kernels). By comparison, an expansion in $M$ basis functions costs $O(M)$ for one evaluation, and typically $M\\sim O(\\log N)$. Basis function methods have an initial cost of at least $O(NM^2+M^3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smoothing parameter(s) $\\lambda$ for kernel methods are typically determined off-line, e.g. using cross-validation, at a cost of $O(N^2)$ flops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular implementations of local regression, such as the $\\textsf{loess}$ function in S-PLUS and R, and the $\\textsf{locfit}$ procedure (Loader, 1999), use triangulation schemes to reduce the computations. They compute the fit exactly at $M$ carefully chosen locations ($O(NM)$), and then use blending techniques to interpolate the fit elsewhere ($O(M)$ per evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
